{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f351c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No checkpoints found for wl_key='37788f2da7b474ea00bc6fb1eed26757d78166661c8d2eb93902fbd381340f6e'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 215\u001b[0m\n\u001b[1;32m    209\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m    212\u001b[0m \u001b[38;5;66;03m# ----------------------------- run ----------------------------------------\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \n\u001b[1;32m    214\u001b[0m \u001b[38;5;66;03m# Replace with your WL key:\u001b[39;00m\n\u001b[0;32m--> 215\u001b[0m \u001b[43manalyze_wl_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m37788f2da7b474ea00bc6fb1eed26757d78166661c8d2eb93902fbd381340f6e\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 107\u001b[0m, in \u001b[0;36manalyze_wl_chain\u001b[0;34m(wl_key)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21manalyze_wl_chain\u001b[39m(wl_key: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 107\u001b[0m     ckpt \u001b[38;5;241m=\u001b[39m \u001b[43m_load_chain_tip\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwl_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m     wl \u001b[38;5;241m=\u001b[39m load_wl_latest_from_chain(wl_key)\n\u001b[1;32m    109\u001b[0m     levels  \u001b[38;5;241m=\u001b[39m wl[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlevels\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "Cell \u001b[0;32mIn[1], line 30\u001b[0m, in \u001b[0;36m_load_chain_tip\u001b[0;34m(wl_key)\u001b[0m\n\u001b[1;32m     26\u001b[0m ckpt \u001b[38;5;241m=\u001b[39m store\u001b[38;5;241m.\u001b[39mdb_rw()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwang_landau_ckpt\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mfind_one(\n\u001b[1;32m     27\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwl_key\u001b[39m\u001b[38;5;124m\"\u001b[39m: wl_key}, sort\u001b[38;5;241m=\u001b[39m[(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstep_end\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)]\n\u001b[1;32m     28\u001b[0m )\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ckpt:\n\u001b[0;32m---> 30\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo checkpoints found for wl_key=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwl_key\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ckpt\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No checkpoints found for wl_key='37788f2da7b474ea00bc6fb1eed26757d78166661c8d2eb93902fbd381340f6e'."
     ]
    }
   ],
   "source": [
    "from typing import Any, Mapping, TypedDict, List, Tuple, Dict\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "from phaseedge.storage import store\n",
    "\n",
    "\n",
    "# ----------------------------- types ---------------------------------------\n",
    "\n",
    "class WLData(TypedDict):\n",
    "    levels: np.ndarray\n",
    "    entropy: np.ndarray\n",
    "    histogram: np.ndarray          # stage-local (resets at flatness)\n",
    "    occurrences: np.ndarray        # cumulative (never resets; may be absent in older ckpts)\n",
    "    bin_indices: np.ndarray\n",
    "    dE: float\n",
    "    anchor: float\n",
    "    steps_total: int\n",
    "    m_log: float                   # current _m = ln(f)\n",
    "\n",
    "\n",
    "# ----------------------------- loaders ------------------------------------\n",
    "\n",
    "def _load_chain_tip(wl_key: str) -> Mapping[str, Any]:\n",
    "    ckpt = store.db_rw()[\"wang_landau_ckpt\"].find_one(\n",
    "        {\"wl_key\": wl_key}, sort=[(\"step_end\", -1)]\n",
    "    )\n",
    "    if not ckpt:\n",
    "        raise RuntimeError(f\"No checkpoints found for wl_key={wl_key!r}.\")\n",
    "    return ckpt\n",
    "\n",
    "\n",
    "def load_wl_latest_from_chain(wl_key: str) -> WLData:\n",
    "    ckpt = _load_chain_tip(wl_key)\n",
    "    s: Mapping[str, Any] = ckpt[\"state\"]\n",
    "\n",
    "    bins: np.ndarray = np.asarray(s[\"bin_indices\"], dtype=int)\n",
    "    entropy: np.ndarray = np.asarray(s[\"entropy\"], dtype=float)\n",
    "    hist: np.ndarray = np.asarray(s[\"histogram\"], dtype=int)\n",
    "    occs_raw = s.get(\"occurrences\", [])\n",
    "    occs: np.ndarray = (\n",
    "        np.asarray(occs_raw, dtype=int)\n",
    "        if isinstance(occs_raw, (list, tuple))\n",
    "        else np.zeros_like(hist)\n",
    "    )\n",
    "\n",
    "    anchor: float = 0.0\n",
    "    dE: float = float(s[\"bin_size\"])\n",
    "    levels: np.ndarray = anchor + dE * bins.astype(float)\n",
    "\n",
    "    order = np.argsort(bins)\n",
    "    return WLData(\n",
    "        levels=levels[order],\n",
    "        entropy=entropy[order],\n",
    "        histogram=hist[order],\n",
    "        occurrences=occs[order] if occs.size else np.zeros_like(hist[order]),\n",
    "        bin_indices=bins[order],\n",
    "        dE=dE,\n",
    "        anchor=anchor,\n",
    "        steps_total=int(ckpt[\"step_end\"]),\n",
    "        m_log=float(s[\"mod_factor\"]),  # _m = ln(f)\n",
    "    )\n",
    "\n",
    "\n",
    "def load_mod_schedule(wl_key: str, m0: float = 1.0) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Concatenate per-checkpoint updates into a global schedule of _m (ln f).\"\"\"\n",
    "    coll = store.db_rw()[\"wang_landau_ckpt\"]\n",
    "    ckpts = list(coll.find({\"wl_key\": wl_key}, sort=[(\"step_end\", 1)]))\n",
    "    if not ckpts:\n",
    "        raise RuntimeError(\"No checkpoints found.\")\n",
    "\n",
    "    # Prefer the recorded initial m from the first checkpoint, else fallback to 1.0\n",
    "    m0 = float(ckpts[0][\"state\"].get(\"mod_factor\", m0))\n",
    "\n",
    "    events: List[Tuple[int, float]] = []\n",
    "    for doc in ckpts:\n",
    "        # New schema: top-level mod_updates\n",
    "        for ev in doc.get(\"mod_updates\", []):\n",
    "            events.append((int(ev[\"step\"]), float(ev[\"m\"])))\n",
    "\n",
    "    if events:\n",
    "        events = sorted(set(events), key=lambda t: t[0])\n",
    "        steps = [0] + [st for (st, _) in events]\n",
    "        m_vals = [m0] + [m for (_, m) in events]\n",
    "    else:\n",
    "        tip_steps = int(ckpts[-1][\"step_end\"])\n",
    "        steps = [0, tip_steps]\n",
    "        m_vals = [m0, m0]\n",
    "\n",
    "    return np.asarray(steps, dtype=int), np.asarray(m_vals, dtype=float)\n",
    "\n",
    "\n",
    "def _extend_stair_to(steps: np.ndarray, vals: np.ndarray, right_x: int) -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Ensure a step curve extends horizontally to right_x.\"\"\"\n",
    "    if steps.size == 0:\n",
    "        return np.array([0, right_x], dtype=int), np.array([1.0, 1.0], dtype=float)\n",
    "    if steps[-1] < right_x:\n",
    "        steps = np.append(steps, right_x)\n",
    "        vals  = np.append(vals,  vals[-1])\n",
    "    return steps, vals\n",
    "\n",
    "\n",
    "# ----------------------------- analysis + plotting ------------------------\n",
    "\n",
    "def analyze_wl_chain(wl_key: str) -> None:\n",
    "    ckpt = _load_chain_tip(wl_key)\n",
    "    wl = load_wl_latest_from_chain(wl_key)\n",
    "    levels  = wl[\"levels\"]\n",
    "    entropy = wl[\"entropy\"]\n",
    "    hist    = wl[\"histogram\"]\n",
    "    occ_all = wl[\"occurrences\"]\n",
    "    dE      = wl[\"dE\"]\n",
    "    steps_total = wl[\"steps_total\"]\n",
    "    m_current = wl[\"m_log\"]\n",
    "    steps_m, m_vals = load_mod_schedule(wl_key)\n",
    "\n",
    "    # DOS from entropy\n",
    "    S_shift: np.ndarray = entropy - np.max(entropy) if entropy.size else entropy\n",
    "    DOS: np.ndarray = np.exp(S_shift) if S_shift.size else np.array([])\n",
    "    if DOS.size:\n",
    "        DOS /= DOS.sum()\n",
    "\n",
    "    # Cv(T)\n",
    "    kB: float = 8.617333262e-5  # eV/K\n",
    "    E:  np.ndarray = levels.astype(float)\n",
    "    E_rr: np.ndarray = E - E.min() if E.size else E\n",
    "    Ts: np.ndarray = np.linspace(100.0, 1500.0, 200)\n",
    "\n",
    "    def _weights(T: float) -> np.ndarray:\n",
    "        return np.exp(S_shift - E_rr / (kB * T))\n",
    "\n",
    "    if E.size:\n",
    "        Z  = np.array([_weights(T).sum() for T in Ts])\n",
    "        U  = np.array([(_weights(T) * E).sum() / Z[i] for i, T in enumerate(Ts)])\n",
    "        U2 = np.array([(_weights(T) * E * E).sum() / Z[i] for i, T in enumerate(Ts)])\n",
    "        Cv = (U2 - U * U) / (kB * Ts * Ts)\n",
    "    else:\n",
    "        Z = U = U2 = Cv = np.array([])\n",
    "\n",
    "    # ---- reporting ----\n",
    "    print(f\"visited bins: {levels.size} | ΔE={dE}\")\n",
    "    print(f\"total steps (chain tip): {steps_total:,}\")\n",
    "    print(f\"current _m (ln f): {m_current:.6g}  (target ≈ 1e-7)\")\n",
    "    print(f\"stage histogram sum: {int(hist.sum())} | cumulative occurrences sum: {int(occ_all.sum())}\")\n",
    "\n",
    "    # ---- sample statistics (new schema: top-level fields) ----\n",
    "    bin_samples = ckpt.get(\"bin_samples\", [])\n",
    "    samples_per_bin = int(ckpt.get(\"samples_per_bin\", 0))\n",
    "\n",
    "    if bin_samples and samples_per_bin > 0:\n",
    "        bins_to_occ: Dict[int, List[list[int]]] = defaultdict(list)\n",
    "        for rec in bin_samples:\n",
    "            try:\n",
    "                b = int(rec[\"bin\"])\n",
    "                occ = rec[\"occ\"]\n",
    "            except Exception:\n",
    "                continue\n",
    "            bins_to_occ[b].append(occ)\n",
    "\n",
    "        n_bins_with_samples = len(bins_to_occ)\n",
    "        n_bins_full = sum(1 for occs in bins_to_occ.values() if len(occs) >= samples_per_bin)\n",
    "        total_samples = sum(len(v) for v in bins_to_occ.values())\n",
    "        mean_per_sampled_bin = (total_samples / n_bins_with_samples) if n_bins_with_samples else 0.0\n",
    "\n",
    "        print(f\"sample capture: {n_bins_with_samples} bins with samples\")\n",
    "        print(f\"bins filled to quota ({samples_per_bin}): {n_bins_full}\")\n",
    "        print(f\"total stored samples: {total_samples}  (avg {mean_per_sampled_bin:.2f} per sampled bin)\")\n",
    "    else:\n",
    "        print(\"sample capture: none recorded in this checkpoint\")\n",
    "\n",
    "    # ---- plotting ----\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(12, 9), constrained_layout=True)\n",
    "\n",
    "    ax = axs[0, 0]\n",
    "    if DOS.size:\n",
    "        eps = 0.0 if np.all(DOS > 0) else 1e-300\n",
    "        ax.semilogy(E, DOS + eps)\n",
    "    ax.set_xlabel(\"E (eV / supercell)\")\n",
    "    ax.set_ylabel(\"DOS (arb., log y)\")\n",
    "    ax.set_title(\"Density of States\")\n",
    "\n",
    "    ax = axs[0, 1]\n",
    "    if Cv.size:\n",
    "        ax.plot(Ts, Cv)\n",
    "    ax.set_xlabel(\"T (K)\")\n",
    "    ax.set_ylabel(\"C$_v$ (eV/K per supercell)\")\n",
    "    ax.set_title(\"Heat Capacity from WL\")\n",
    "\n",
    "    ax = axs[1, 0]\n",
    "    y_visits = hist if hist.sum() > 0 else occ_all\n",
    "    label = \"Histogram (stage)\" if y_visits is hist else \"Occurrences (cumulative)\"\n",
    "    if y_visits.size:\n",
    "        ax.plot(E, y_visits)\n",
    "    ax.set_xlabel(\"E (eV / supercell)\")\n",
    "    ax.set_ylabel(\"Visits\")\n",
    "    ax.set_title(f\"WL {label}\")\n",
    "\n",
    "    ax = axs[1, 1]\n",
    "    right_x = max(int(steps_total), int(steps_m[-1]) if steps_m.size else 0)\n",
    "    steps_m_ext, m_vals_ext = _extend_stair_to(steps_m, m_vals, right_x)\n",
    "    ax.step(steps_m_ext, m_vals_ext, where=\"post\")\n",
    "    ax.set_xlim(0, right_x)\n",
    "    ax.set_xlabel(\"MC steps\")\n",
    "    ax.set_ylabel(\"_m = ln(f)\")\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_title(\"WL Modification Schedule (_m)\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ----------------------------- run ----------------------------------------\n",
    "\n",
    "# Replace with your WL key:\n",
    "analyze_wl_chain(\"78c3ba04732425012a68216c8fe21baf5e0c1243b6f1b8003666fbe853011a73\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atomate2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
