{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5880a462",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cbu/miniconda3/envs/cms/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "══════════════════════════════════════════════════════════════════════════════════════\n",
      "═══════════════════════════════════ CE Comparison ════════════════════════════════════\n",
      "══════════════════════════════════════════════════════════════════════════════════════\n",
      "Refined CE key     : 0c5b7a6930102e3ee48ae6f28aec48bcba181402c2acde5ba77704c97db2b177\n",
      "Base (composition) : 11a657d3fc1372898856817e9576d01355520acdf466f33b572359197e6f7426\n",
      "Prototype          : spinel16c_Q0Cl\n",
      "Supercell diag     : (2, 2, 2)  (n_prims=8, sites/prim=10)\n",
      "\n",
      "Performance (per-site, meV) — Base CE evaluated on refined dataset  vs  Refined CE stored 5-fold CV\n",
      " Metric              │ Base CE (OOS on refined set) │ Refined CE (5-fold CV, stored) \n",
      "─────────────────────────────────────────────────────────────────────────────────────────\n",
      " n                   │ 500                          │ 500                            \n",
      " MAE (meV/site)      │ 22.039                       │ 6.963                          \n",
      " RMSE (meV/site)     │ 29.465                       │ 8.796                          \n",
      " Max|err| (meV/site) │ 80.545                       │ 26.566                         \n",
      "\n",
      "Verdict A      : Better: Refined CE (5-fold CV, stored) (MAE ↓ by 15.075 meV/site, RMSE ↓ by 20.669 meV/site).\n",
      "Performance (per-site, meV) — Base CE stored 5-fold CV  vs  Refined CE evaluated on base dataset\n",
      " Metric              │ Base CE (5-fold CV, stored) │ Refined CE (OOS on base set) \n",
      "──────────────────────────────────────────────────────────────────────────────────────\n",
      " n                   │ 102                         │ 102                          \n",
      " MAE (meV/site)      │ 8.026                       │ 6.226                        \n",
      " RMSE (meV/site)     │ 10.341                      │ 7.713                        \n",
      " Max|err| (meV/site) │ 39.481                      │ 20.418                       \n",
      "\n",
      "Verdict B      : Better: Refined CE (OOS on base set) (MAE ↓ by 1.801 meV/site, RMSE ↓ by 2.629 meV/site).\n",
      "══════════════════════════════════════════════════════════════════════════════════════\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'refined_ce_key': '0c5b7a6930102e3ee48ae6f28aec48bcba181402c2acde5ba77704c97db2b177',\n",
       " 'base_ce_key': '11a657d3fc1372898856817e9576d01355520acdf466f33b572359197e6f7426',\n",
       " 'n_prims': 8,\n",
       " 'sites_per_prim': 10,\n",
       " 'base_on_refined_stats_per_site': {'n': 500,\n",
       "  'mae_per_site': 0.022038559109991338,\n",
       "  'rmse_per_site': 0.029465411421590346,\n",
       "  'max_abs_per_site': 0.0805451287307335},\n",
       " 'refined_cv_stats_per_site': {'n': 500,\n",
       "  'mae_per_site': 0.0069634943471185515,\n",
       "  'rmse_per_site': 0.008796481862236702,\n",
       "  'max_abs_per_site': 0.026566101216257465},\n",
       " 'refined_on_base_stats_per_site': {'n': 102,\n",
       "  'mae_per_site': 0.0062258414841970585,\n",
       "  'rmse_per_site': 0.007712783391994033,\n",
       "  'max_abs_per_site': 0.02041815321230711},\n",
       " 'base_cv_stats_per_site': {'n': 102,\n",
       "  'mae_per_site': 0.008026480751031517,\n",
       "  'rmse_per_site': 0.010341332573649442,\n",
       "  'max_abs_per_site': 0.03948092140349413},\n",
       " 'design_metrics': {'base': {'n_samples': 102,\n",
       "   'n_features': 1395,\n",
       "   'rank': 43,\n",
       "   'sigma_max': 277.6701464908878,\n",
       "   'sigma_min': 2.4598172693833824,\n",
       "   'condition_number': 112.8824282791108,\n",
       "   'logdet_xtx': 265.0097421128455,\n",
       "   'leverage_mean': 0.42156862745098034,\n",
       "   'leverage_max': 0.8259145634170014,\n",
       "   'leverage_p95': 0.6219677105879211,\n",
       "   'weighting_applied': True,\n",
       "   'standardization': 'column_zscore',\n",
       "   'zero_variance_feature_count': 5},\n",
       "  'refined': {'n_samples': 500,\n",
       "   'n_features': 1395,\n",
       "   'rank': 44,\n",
       "   'sigma_max': 557.7492254115239,\n",
       "   'sigma_min': 2.6525448644597047e-12,\n",
       "   'condition_number': 210269478524025.44,\n",
       "   'logdet_xtx': 294.0495660893356,\n",
       "   'leverage_mean': 0.08799999999999998,\n",
       "   'leverage_max': 0.1599968378660737,\n",
       "   'leverage_p95': 0.12329395346647175,\n",
       "   'weighting_applied': True,\n",
       "   'standardization': 'column_zscore',\n",
       "   'zero_variance_feature_count': 5}}}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Any, Mapping, Sequence, cast\n",
    "import numpy as np\n",
    "\n",
    "from pymatgen.core import Structure\n",
    "from smol.cofe import ClusterExpansion\n",
    "\n",
    "# ---- phaseedge imports (modern-only) ----\n",
    "from phaseedge.jobs.store_ce_model import lookup_ce_by_key\n",
    "from phaseedge.jobs.train_ce import (\n",
    "    featurize_structures,\n",
    "    lookup_train_refs_by_key,\n",
    "    predict_from_features,\n",
    "    compute_stats,\n",
    "    _n_replace_sites_from_prototype,\n",
    ")\n",
    "from phaseedge.schemas.mixture import Mixture, sublattices_from_mixtures\n",
    "from phaseedge.storage.store import lookup_total_energy_eV\n",
    "from phaseedge.utils.keys import occ_key_for_structure\n",
    "\n",
    "\n",
    "# ----------------- small helpers -----------------\n",
    "\n",
    "def fmt_mev(x: float | str) -> str:\n",
    "    if isinstance(x, str):\n",
    "        return x\n",
    "    return f\"{1e3 * float(x):.3f}\"\n",
    "\n",
    "\n",
    "def _gather_composition_mixtures(sources: Sequence[Mapping[str, Any]]) -> list[Mixture]:\n",
    "    mixes: list[Mixture] = []\n",
    "    for s in sources:\n",
    "        if str(s.get(\"type\", \"\")).lower() != \"composition\":\n",
    "            continue\n",
    "        for m in s.get(\"mixtures\", []):\n",
    "            mixes.append(\n",
    "                Mixture.from_dict(\n",
    "                    {\n",
    "                        \"composition_map\": dict(m[\"composition_map\"]),\n",
    "                        \"K\": int(m[\"K\"]),\n",
    "                        \"seed\": int(m[\"seed\"]),\n",
    "                    }\n",
    "                )\n",
    "            )\n",
    "    if not mixes:\n",
    "        raise RuntimeError(\"Expected 'composition' mixtures in sources (modern schema).\")\n",
    "    return mixes\n",
    "\n",
    "\n",
    "def _sublattices_for_doc(doc: Mapping[str, Any]) -> dict[str, tuple[str, ...]]:\n",
    "    \"\"\"\n",
    "    Replaceable sublattices for per-site scaling:\n",
    "      - composition CE: from this doc's mixtures\n",
    "      - wl_refined CE : from the base (composition) CE's mixtures\n",
    "    \"\"\"\n",
    "    sources = cast(Sequence[Mapping[str, Any]], doc[\"sources\"])\n",
    "    if not sources:\n",
    "        raise RuntimeError(\"CE document missing 'sources'.\")\n",
    "    s0 = sources[0]\n",
    "    s_type = str(s0.get(\"type\", \"\")).lower()\n",
    "\n",
    "    if s_type == \"composition\":\n",
    "        return sublattices_from_mixtures(_gather_composition_mixtures(sources))\n",
    "\n",
    "    if s_type == \"dopt_sampling_intent\":\n",
    "        base_ce_key = cast(str, s0[\"base_ce_key\"])\n",
    "        base_doc = lookup_ce_by_key(base_ce_key)\n",
    "        if not base_doc:\n",
    "            raise RuntimeError(f\"Base CE not found for dopt_sampling_intent source: {base_ce_key}\")\n",
    "        return sublattices_from_mixtures(\n",
    "            _gather_composition_mixtures(cast(Sequence[Mapping[str, Any]], base_doc[\"sources\"]))\n",
    "        )\n",
    "\n",
    "    raise RuntimeError(f\"Unsupported source type in CE doc: {s_type!r}\")\n",
    "\n",
    "\n",
    "def _fmt_f(x: float) -> str:\n",
    "    return f\"{float(x):.6g}\"\n",
    "\n",
    "\n",
    "def _grab(dm: Mapping[str, Any] | None, key: str, default: Any) -> Any:\n",
    "    return default if dm is None else dm.get(key, default)\n",
    "\n",
    "\n",
    "def _print_two_col_table(title: str, col_a_name: str, col_b_name: str, rows: list[tuple[str, str, str]]) -> None:\n",
    "    \"\"\"Pretty side-by-side ASCII table.\"\"\"\n",
    "    w_name = max(len(r[0]) for r in rows + [(\"Metric\", \"\", \"\")])\n",
    "    w_a = max(len(col_a_name), max(len(r[1]) for r in rows))\n",
    "    w_b = max(len(col_b_name), max(len(r[2]) for r in rows))\n",
    "    total = 3 + w_name + 3 + w_a + 3 + w_b + 3\n",
    "\n",
    "    print(title.center(total, \"─\"))\n",
    "    print(f\" {'Metric'.ljust(w_name)} │ {col_a_name.ljust(w_a)} │ {col_b_name.ljust(w_b)} \")\n",
    "    print(\"─\" * total)\n",
    "    for name, a, b in rows:\n",
    "        print(f\" {name.ljust(w_name)} │ {a.ljust(w_a)} │ {b.ljust(w_b)} \")\n",
    "    print(\"\")\n",
    "\n",
    "\n",
    "def _cmp(a: float, b: float, *, atol: float, rtol: float) -> int:\n",
    "    \"\"\"\n",
    "    Compare a vs b with tolerances.\n",
    "      -1 if a < b beyond tol\n",
    "       0 if |a-b| <= tol\n",
    "       1 if a > b beyond tol\n",
    "    \"\"\"\n",
    "    tol = max(atol, rtol * abs(b))\n",
    "    if a < b - tol:\n",
    "        return -1\n",
    "    if a > b + tol:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "\n",
    "def _better_text(\n",
    "    label_left: str,\n",
    "    label_right: str,\n",
    "    *,\n",
    "    mae_left: float,\n",
    "    rmse_left: float,\n",
    "    mae_right: float,\n",
    "    rmse_right: float,\n",
    "    atol: float,\n",
    "    rtol: float,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Produce a human-readable verdict that *always* names which is better\n",
    "    when there is a clear winner; otherwise reports 'Comparable' or 'No clear winner'.\n",
    "    \"\"\"\n",
    "    c_mae = _cmp(mae_left, mae_right, atol=atol, rtol=rtol)\n",
    "    c_rmse = _cmp(rmse_left, rmse_right, atol=atol, rtol=rtol)\n",
    "\n",
    "    d_mae = abs(mae_left - mae_right)\n",
    "    d_rmse = abs(rmse_left - rmse_right)\n",
    "\n",
    "    if c_mae == -1 and c_rmse == -1:\n",
    "        # left better\n",
    "        return (\n",
    "            f\"Better: {label_left} \"\n",
    "            f\"(MAE ↓ by {fmt_mev(d_mae)} meV/site, RMSE ↓ by {fmt_mev(d_rmse)} meV/site).\"\n",
    "        )\n",
    "    if c_mae == 1 and c_rmse == 1:\n",
    "        # right better\n",
    "        return (\n",
    "            f\"Better: {label_right} \"\n",
    "            f\"(MAE ↓ by {fmt_mev(d_mae)} meV/site, RMSE ↓ by {fmt_mev(d_rmse)} meV/site).\"\n",
    "        )\n",
    "    if c_mae == 0 and c_rmse == 0:\n",
    "        return (\n",
    "            \"Comparable within tolerance \"\n",
    "            f\"(ΔMAE≈{fmt_mev(d_mae)} meV/site, ΔRMSE≈{fmt_mev(d_rmse)} meV/site).\"\n",
    "        )\n",
    "\n",
    "    # mixed case: one metric favors left, the other favors right\n",
    "    pieces: list[str] = []\n",
    "    if c_mae == -1:\n",
    "        pieces.append(f\"{label_left} has lower MAE by {fmt_mev(d_mae)} meV/site\")\n",
    "    elif c_mae == 1:\n",
    "        pieces.append(f\"{label_right} has lower MAE by {fmt_mev(d_mae)} meV/site\")\n",
    "    if c_rmse == -1:\n",
    "        pieces.append(f\"{label_left} has lower RMSE by {fmt_mev(d_rmse)} meV/site\")\n",
    "    elif c_rmse == 1:\n",
    "        pieces.append(f\"{label_right} has lower RMSE by {fmt_mev(d_rmse)} meV/site\")\n",
    "    return \"No clear winner: \" + \"; \".join(pieces) + \".\"\n",
    "\n",
    "\n",
    "def _load_structures_and_energies(\n",
    "    *,\n",
    "    dataset_key: str,\n",
    "    model: str,\n",
    "    relax_cell: bool,\n",
    ") -> tuple[list[Structure], list[float]]:\n",
    "    \"\"\"\n",
    "    Load structures and *supercell* total energies for a dataset key.\n",
    "    \"\"\"\n",
    "    train_refs = lookup_train_refs_by_key(dataset_key)\n",
    "    if not train_refs:\n",
    "        raise RuntimeError(f\"Dataset {dataset_key} missing 'train_refs'.\")\n",
    "\n",
    "    structures: list[Structure] = []\n",
    "    energies_eV_super: list[float] = []\n",
    "\n",
    "    for i, r in enumerate(train_refs):\n",
    "        # sanity: occ_key should round-trip from structure\n",
    "        ok2 = occ_key_for_structure(r[\"structure\"])\n",
    "        ok_expected = cast(str, r[\"occ_key\"])\n",
    "        if ok2 != ok_expected:\n",
    "            raise RuntimeError(\n",
    "                f\"train_refs[{i}] occ_key mismatch: expected {ok_expected}, rebuilt {ok2}.\"\n",
    "            )\n",
    "\n",
    "        E = lookup_total_energy_eV(\n",
    "            set_id=cast(str, r[\"set_id\"]),\n",
    "            occ_key=ok_expected,\n",
    "            model=model,\n",
    "            relax_cell=relax_cell,\n",
    "        )\n",
    "        if E is None:\n",
    "            raise RuntimeError(\n",
    "                f\"Energy not found in store for train_refs[{i}] set_id={r['set_id']}, occ_key={ok_expected[:12]}...\"\n",
    "            )\n",
    "\n",
    "        structures.append(r[\"structure\"])\n",
    "        energies_eV_super.append(E)\n",
    "\n",
    "    return structures, energies_eV_super\n",
    "\n",
    "\n",
    "def _predict_per_prim(\n",
    "    ce: ClusterExpansion,\n",
    "    *,\n",
    "    structures: list[Structure],\n",
    "    supercell_diag: tuple[int, int, int],\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Predict energy per-primitive using CE coefficients and features.\n",
    "    \"\"\"\n",
    "    _, X = featurize_structures(\n",
    "        subspace=ce.cluster_subspace,\n",
    "        structures=structures,\n",
    "        supercell_diag=supercell_diag,\n",
    "    )\n",
    "    coefs = np.asarray(getattr(ce, \"coefs\"), dtype=np.float64)\n",
    "    y_pred_per_prim = predict_from_features(X, coefs)\n",
    "    return y_pred_per_prim\n",
    "\n",
    "\n",
    "# ----------------- main comparison -----------------\n",
    "\n",
    "def compare_comp_vs_refined_on_refined_dataset(\n",
    "    refined_ce_key: str,\n",
    "    *,\n",
    "    atol: float = 1e-6,\n",
    "    rtol: float = 1e-8,\n",
    "    verbose: bool = True,\n",
    ") -> dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Cross-compare base composition CE and refined WL CE.\n",
    "\n",
    "    Inputs:\n",
    "      - refined_ce_key: key of a **refined WL CE**.\n",
    "\n",
    "    What it prints (per-site, meV), refined is always the RIGHT column:\n",
    "      1) Base CE evaluated on the *refined* dataset  (left)  vs  Refined CE stored 5-fold CV  (right)\n",
    "      2) Base CE stored 5-fold CV                     (left)  vs  Refined CE evaluated on the *base* dataset (right)\n",
    "\n",
    "    Returns (dict):\n",
    "      - refined_ce_key, base_ce_key, n_prims, sites_per_prim\n",
    "      - base_on_refined_stats_per_site\n",
    "      - refined_cv_stats_per_site\n",
    "      - refined_on_base_stats_per_site\n",
    "      - base_cv_stats_per_site\n",
    "      - design_metrics: {base, refined}\n",
    "    \"\"\"\n",
    "    # --- Load refined CE doc ---\n",
    "    ref_doc = lookup_ce_by_key(refined_ce_key)\n",
    "    if not ref_doc:\n",
    "        raise RuntimeError(f\"No CE found for refined_ce_key={refined_ce_key}\")\n",
    "\n",
    "    sources = cast(Sequence[Mapping[str, Any]], ref_doc[\"sources\"])\n",
    "    if not sources:\n",
    "        raise RuntimeError(\"Refined CE doc has no sources.\")\n",
    "    s0 = sources[0]\n",
    "    s_type = str(s0.get(\"type\", \"\")).lower()\n",
    "    if s_type != \"dopt_sampling_intent\":\n",
    "        raise RuntimeError(f\"Provided CE is not a dopt_sampling_intent CE (source.type={s_type!r}).\")\n",
    "\n",
    "    base_ce_key = cast(str, s0[\"base_ce_key\"])\n",
    "    base_doc = lookup_ce_by_key(base_ce_key)\n",
    "    if not base_doc:\n",
    "        raise RuntimeError(f\"Base (composition) CE not found: {base_ce_key}\")\n",
    "\n",
    "    # --- Basic identity checks (should match in the modern pipeline) ---\n",
    "    r_proto = ref_doc[\"prototype\"]\n",
    "    b_proto = base_doc[\"prototype\"]\n",
    "    if r_proto != b_proto:\n",
    "        raise RuntimeError(\"Prototype mismatch between refined CE and base composition CE.\")\n",
    "    r_pp = cast(Mapping[str, Any], ref_doc[\"prototype_params\"])\n",
    "    b_pp = cast(Mapping[str, Any], base_doc[\"prototype_params\"])\n",
    "    if dict(r_pp) != dict(b_pp):\n",
    "        raise RuntimeError(\"prototype_params mismatch between refined CE and base composition CE.\")\n",
    "    \n",
    "    xs, ys, zs = ref_doc[\"supercell_diag\"]\n",
    "    r_sc = (int(xs), int(ys), int(zs))\n",
    "    b_xs, b_ys, b_zs = base_doc[\"supercell_diag\"]\n",
    "    b_sc = (int(b_xs), int(b_ys), int(b_zs))\n",
    "    if r_sc != b_sc:\n",
    "        raise RuntimeError(\"supercell_diag mismatch between refined CE and base composition CE.\")\n",
    "\n",
    "    # --- Per-site scaling (replaceable sites / primitive) ---\n",
    "    sublattices = _sublattices_for_doc(base_doc)  # composition-ground truth\n",
    "    n_prims = int(np.prod(np.asarray(r_sc, dtype=int)))\n",
    "    n_sites_const = _n_replace_sites_from_prototype(\n",
    "        prototype=r_proto,\n",
    "        prototype_params=r_pp,\n",
    "        supercell_diag=r_sc,\n",
    "        sublattices=sublattices,\n",
    "    )\n",
    "    if n_sites_const % n_prims != 0:\n",
    "        raise RuntimeError(\"sites_per_supercell not divisible by n_prims (prototype/sublattice mismatch).\")\n",
    "    sites_per_prim = n_sites_const // n_prims\n",
    "    scale_site = 1.0 / float(sites_per_prim)\n",
    "\n",
    "    # --- Build refined dataset from refined CE train_refs (structures + energies) ---\n",
    "    model_r = cast(str, ref_doc[\"model\"])\n",
    "    relax_cell_r = bool(ref_doc[\"relax_cell\"])\n",
    "\n",
    "    structures_refined, energies_eV_super_refined = _load_structures_and_energies(\n",
    "        dataset_key=cast(str, ref_doc[\"dataset_key\"]),\n",
    "        model=model_r,\n",
    "        relax_cell=relax_cell_r,\n",
    "    )\n",
    "    y_true_per_prim_refined = (np.asarray(energies_eV_super_refined, dtype=np.float64) / float(n_prims)).astype(np.float64, copy=False)\n",
    "\n",
    "    # --- Evaluate BASE CE on the refined dataset ---\n",
    "    base_ce = ClusterExpansion.from_dict(cast(Mapping[str, Any], base_doc[\"payload\"]))\n",
    "    y_pred_per_prim_base_on_refined = _predict_per_prim(\n",
    "        base_ce,\n",
    "        structures=structures_refined,\n",
    "        supercell_diag=r_sc,\n",
    "    )\n",
    "    base_on_refined_stats = compute_stats(\n",
    "        (y_true_per_prim_refined * scale_site).tolist(),\n",
    "        (y_pred_per_prim_base_on_refined * scale_site).tolist(),\n",
    "    )  # per-site\n",
    "\n",
    "    # --- Pull refined CE stored 5-fold CV stats (per-site) ---\n",
    "    ref_stats = cast(Mapping[str, Any], ref_doc[\"stats\"])\n",
    "    ref_cv = cast(Mapping[str, Any], ref_stats[\"five_fold_cv\"])\n",
    "    # also harvest design metrics (stored at training time)\n",
    "    dm_base = cast(Mapping[str, Any] | None, base_doc.get(\"design_metrics\"))\n",
    "    dm_ref = cast(Mapping[str, Any] | None, ref_doc.get(\"design_metrics\"))\n",
    "\n",
    "    # --- Evaluate REFINED CE on the base dataset ---\n",
    "    model_b = cast(str, base_doc[\"model\"])\n",
    "    relax_cell_b = bool(base_doc[\"relax_cell\"])\n",
    "\n",
    "    structures_base, energies_eV_super_base = _load_structures_and_energies(\n",
    "        dataset_key=cast(str, base_doc[\"dataset_key\"]),\n",
    "        model=model_b,\n",
    "        relax_cell=relax_cell_b,\n",
    "    )\n",
    "    y_true_per_prim_base = (np.asarray(energies_eV_super_base, dtype=np.float64) / float(n_prims)).astype(np.float64, copy=False)\n",
    "\n",
    "    refined_ce = ClusterExpansion.from_dict(cast(Mapping[str, Any], ref_doc[\"payload\"]))\n",
    "    y_pred_per_prim_refined_on_base = _predict_per_prim(\n",
    "        refined_ce,\n",
    "        structures=structures_base,\n",
    "        supercell_diag=b_sc,  # == r_sc\n",
    "    )\n",
    "    refined_on_base_stats = compute_stats(\n",
    "        (y_true_per_prim_base * scale_site).tolist(),\n",
    "        (y_pred_per_prim_refined_on_base * scale_site).tolist(),\n",
    "    )  # per-site\n",
    "\n",
    "    # --- Base CE stored 5-fold CV (per-site) ---\n",
    "    base_stats = cast(Mapping[str, Any], base_doc[\"stats\"])\n",
    "    base_cv = cast(Mapping[str, Any], base_stats[\"five_fold_cv\"])\n",
    "\n",
    "    # --- Pretty side-by-side printout (refined is ALWAYS right column) ---\n",
    "    if verbose:\n",
    "        print(\"═\" * 86)\n",
    "        print(\" CE Comparison \".center(86, \"═\"))\n",
    "        print(\"═\" * 86)\n",
    "        print(f\"Refined CE key     : {refined_ce_key}\")\n",
    "        print(f\"Base (composition) : {base_ce_key}\")\n",
    "        print(f\"Prototype          : {r_proto}\")\n",
    "        print(f\"Supercell diag     : {r_sc}  (n_prims={n_prims}, sites/prim={sites_per_prim})\")\n",
    "        print(\"\")\n",
    "\n",
    "        # 1) Performance: Base CE on refined dataset (left) vs Refined CE stored CV (right)\n",
    "        left_label_1 = \"Base CE (OOS on refined set)\"\n",
    "        right_label_1 = \"Refined CE (5-fold CV, stored)\"\n",
    "        perf_rows_1: list[tuple[str, str, str]] = [\n",
    "            (\"n\",                   str(int(base_on_refined_stats[\"n\"])),                 str(int(ref_cv[\"n\"]))),\n",
    "            (\"MAE (meV/site)\",      fmt_mev(base_on_refined_stats[\"mae_per_site\"]),       fmt_mev(float(ref_cv[\"mae_per_site\"]))),\n",
    "            (\"RMSE (meV/site)\",     fmt_mev(base_on_refined_stats[\"rmse_per_site\"]),      fmt_mev(float(ref_cv[\"rmse_per_site\"]))),\n",
    "            (\"Max|err| (meV/site)\", fmt_mev(base_on_refined_stats[\"max_abs_per_site\"]),   fmt_mev(float(ref_cv[\"max_abs_per_site\"]))),\n",
    "        ]\n",
    "        _print_two_col_table(\n",
    "            title=\"Performance (per-site, meV) — Base CE evaluated on refined dataset  vs  Refined CE stored 5-fold CV\",\n",
    "            col_a_name=left_label_1,\n",
    "            col_b_name=right_label_1,\n",
    "            rows=perf_rows_1,\n",
    "        )\n",
    "\n",
    "        verdict1 = _better_text(\n",
    "            left_label_1, right_label_1,\n",
    "            mae_left=float(base_on_refined_stats[\"mae_per_site\"]),\n",
    "            rmse_left=float(base_on_refined_stats[\"rmse_per_site\"]),\n",
    "            mae_right=float(ref_cv[\"mae_per_site\"]),\n",
    "            rmse_right=float(ref_cv[\"rmse_per_site\"]),\n",
    "            atol=atol, rtol=rtol,\n",
    "        )\n",
    "        print(f\"Verdict A      : {verdict1}\")\n",
    "\n",
    "        # 2) Performance: Base CE stored CV (left) vs Refined CE on base dataset (right)\n",
    "        left_label_2 = \"Base CE (5-fold CV, stored)\"\n",
    "        right_label_2 = \"Refined CE (OOS on base set)\"\n",
    "        perf_rows_2: list[tuple[str, str, str]] = [\n",
    "            (\"n\",                   str(int(base_cv[\"n\"])),                               str(int(refined_on_base_stats[\"n\"]))),\n",
    "            (\"MAE (meV/site)\",      fmt_mev(float(base_cv[\"mae_per_site\"])),              fmt_mev(refined_on_base_stats[\"mae_per_site\"])),\n",
    "            (\"RMSE (meV/site)\",     fmt_mev(float(base_cv[\"rmse_per_site\"])),             fmt_mev(refined_on_base_stats[\"rmse_per_site\"])),\n",
    "            (\"Max|err| (meV/site)\", fmt_mev(float(base_cv[\"max_abs_per_site\"])),          fmt_mev(refined_on_base_stats[\"max_abs_per_site\"])),\n",
    "        ]\n",
    "        _print_two_col_table(\n",
    "            title=\"Performance (per-site, meV) — Base CE stored 5-fold CV  vs  Refined CE evaluated on base dataset\",\n",
    "            col_a_name=left_label_2,\n",
    "            col_b_name=right_label_2,\n",
    "            rows=perf_rows_2,\n",
    "        )\n",
    "\n",
    "        verdict2 = _better_text(\n",
    "            left_label_2, right_label_2,\n",
    "            mae_left=float(base_cv[\"mae_per_site\"]),\n",
    "            rmse_left=float(base_cv[\"rmse_per_site\"]),\n",
    "            mae_right=float(refined_on_base_stats[\"mae_per_site\"]),\n",
    "            rmse_right=float(refined_on_base_stats[\"rmse_per_site\"]),\n",
    "            atol=atol, rtol=rtol,\n",
    "        )\n",
    "        print(f\"Verdict B      : {verdict2}\")\n",
    "        print(\"═\" * 86)\n",
    "\n",
    "    return {\n",
    "        \"refined_ce_key\": refined_ce_key,\n",
    "        \"base_ce_key\": base_ce_key,\n",
    "        \"n_prims\": n_prims,\n",
    "        \"sites_per_prim\": sites_per_prim,\n",
    "        \"base_on_refined_stats_per_site\": base_on_refined_stats,\n",
    "        \"refined_cv_stats_per_site\": ref_cv,\n",
    "        \"refined_on_base_stats_per_site\": refined_on_base_stats,\n",
    "        \"base_cv_stats_per_site\": base_cv,\n",
    "        \"design_metrics\": {\n",
    "            \"base\": dm_base,\n",
    "            \"refined\": dm_ref,\n",
    "        },\n",
    "    }\n",
    "\n",
    "\n",
    "# ---- Example:\n",
    "compare_comp_vs_refined_on_refined_dataset(\"0c5b7a6930102e3ee48ae6f28aec48bcba181402c2acde5ba77704c97db2b177\") # 500\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
