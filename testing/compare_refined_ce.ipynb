{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5880a462",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cbu/miniconda3/envs/cms/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "══════════════════════════════════════════════════════════════════════════════════════\n",
      "═══════════════════════════════════ CE Comparison ════════════════════════════════════\n",
      "══════════════════════════════════════════════════════════════════════════════════════\n",
      "Refined CE key     : 4d22ca1a5ff7bd78f6bfbb20e8938ab03c63ec76fe6050f6410969ac1f333cf2\n",
      "Base (composition) : 1d425e574c86cc084ae98e7aa5a686efbb33a1877b7fe49be542d182d193a7f8\n",
      "Prototype          : spinel16c_Q0Cl\n",
      "Supercell diag     : (2, 2, 2)  (n_prims=8, sites/prim=10)\n",
      "\n",
      "Performance (per-site, meV) — Base CE evaluated on refined dataset  vs  Refined CE stored 5-fold CV\n",
      " Metric              │ Base CE (OOS on refined set) │ Refined CE (5-fold CV, stored) \n",
      "─────────────────────────────────────────────────────────────────────────────────────────\n",
      " n                   │ 250                          │ 250                            \n",
      " MAE (meV/site)      │ 32.989                       │ 6.499                          \n",
      " RMSE (meV/site)     │ 44.678                       │ 8.466                          \n",
      " Max|err| (meV/site) │ 142.473                      │ 43.539                         \n",
      "\n",
      "Verdict A      : Better: Refined CE (5-fold CV, stored) (MAE ↓ by 26.490 meV/site, RMSE ↓ by 36.211 meV/site).\n",
      "Performance (per-site, meV) — Base CE stored 5-fold CV  vs  Refined CE evaluated on base dataset\n",
      " Metric              │ Base CE (5-fold CV, stored) │ Refined CE (OOS on base set) \n",
      "──────────────────────────────────────────────────────────────────────────────────────\n",
      " n                   │ 102                         │ 102                          \n",
      " MAE (meV/site)      │ 8.155                       │ 5.780                        \n",
      " RMSE (meV/site)     │ 10.644                      │ 7.718                        \n",
      " Max|err| (meV/site) │ 31.025                      │ 23.814                       \n",
      "\n",
      "Verdict B      : Better: Refined CE (OOS on base set) (MAE ↓ by 2.375 meV/site, RMSE ↓ by 2.926 meV/site).\n",
      "══════════════════════════════════════════════════════════════════════════════════════\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'refined_ce_key': '4d22ca1a5ff7bd78f6bfbb20e8938ab03c63ec76fe6050f6410969ac1f333cf2',\n",
       " 'base_ce_key': '1d425e574c86cc084ae98e7aa5a686efbb33a1877b7fe49be542d182d193a7f8',\n",
       " 'n_prims': 8,\n",
       " 'sites_per_prim': 10,\n",
       " 'base_on_refined_stats_per_site': {'n': 250,\n",
       "  'mae_per_site': 0.03298879243376595,\n",
       "  'rmse_per_site': 0.04467754961847559,\n",
       "  'max_abs_per_site': 0.14247281207897444},\n",
       " 'refined_cv_stats_per_site': {'n': 250,\n",
       "  'mae_per_site': 0.006498675617373141,\n",
       "  'rmse_per_site': 0.008466200177717884,\n",
       "  'max_abs_per_site': 0.04353893906426265},\n",
       " 'refined_on_base_stats_per_site': {'n': 102,\n",
       "  'mae_per_site': 0.005780244900756011,\n",
       "  'rmse_per_site': 0.007718491657546254,\n",
       "  'max_abs_per_site': 0.023814300774984254},\n",
       " 'base_cv_stats_per_site': {'n': 102,\n",
       "  'mae_per_site': 0.008154847185094842,\n",
       "  'rmse_per_site': 0.010644238908961708,\n",
       "  'max_abs_per_site': 0.03102492243448296},\n",
       " 'design_metrics': {'base': {'n_samples': 102,\n",
       "   'n_features': 1395,\n",
       "   'rank': 43,\n",
       "   'sigma_max': 278.39649679242893,\n",
       "   'sigma_min': 2.2239866413740224,\n",
       "   'condition_number': 125.17903282927551,\n",
       "   'logdet_xtx': 262.99086529030063,\n",
       "   'leverage_mean': 0.4215686274509804,\n",
       "   'leverage_max': 0.8250586011354519,\n",
       "   'leverage_p95': 0.5972906179770033,\n",
       "   'weighting_applied': True,\n",
       "   'standardization': 'column_zscore',\n",
       "   'zero_variance_feature_count': 5},\n",
       "  'refined': {'n_samples': 250,\n",
       "   'n_features': 1395,\n",
       "   'rank': 44,\n",
       "   'sigma_max': 397.6209622568724,\n",
       "   'sigma_min': 1.4986224734793522e-12,\n",
       "   'condition_number': 265324302346618.2,\n",
       "   'logdet_xtx': 264.6348578555298,\n",
       "   'leverage_mean': 0.176,\n",
       "   'leverage_max': 0.28647190612204065,\n",
       "   'leverage_p95': 0.2528582772445933,\n",
       "   'weighting_applied': True,\n",
       "   'standardization': 'column_zscore',\n",
       "   'zero_variance_feature_count': 5}}}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Any, Mapping, Sequence, cast\n",
    "import numpy as np\n",
    "\n",
    "from pymatgen.core import Structure\n",
    "from smol.cofe import ClusterExpansion\n",
    "\n",
    "# ---- phaseedge imports (modern-only) ----\n",
    "from phaseedge.jobs.store_ce_model import lookup_ce_by_key\n",
    "from phaseedge.jobs.train_ce import (\n",
    "    featurize_structures,\n",
    "    predict_from_features,\n",
    "    compute_stats,\n",
    "    _n_replace_sites_from_prototype,\n",
    ")\n",
    "from phaseedge.storage.cetrainref_dataset import Dataset\n",
    "from phaseedge.science.prototype_spec import PrototypeSpec\n",
    "\n",
    "\n",
    "# ----------------- small helpers -----------------\n",
    "\n",
    "def fmt_mev(x: float | str) -> str:\n",
    "    if isinstance(x, str):\n",
    "        return x\n",
    "    return f\"{1e3 * float(x):.3f}\"\n",
    "\n",
    "\n",
    "def _print_two_col_table(title: str, col_a_name: str, col_b_name: str, rows: list[tuple[str, str, str]]) -> None:\n",
    "    \"\"\"Pretty side-by-side ASCII table.\"\"\"\n",
    "    w_name = max(len(r[0]) for r in rows + [(\"Metric\", \"\", \"\")])\n",
    "    w_a = max(len(col_a_name), max(len(r[1]) for r in rows))\n",
    "    w_b = max(len(col_b_name), max(len(r[2]) for r in rows))\n",
    "    total = 3 + w_name + 3 + w_a + 3 + w_b + 3\n",
    "\n",
    "    print(title.center(total, \"─\"))\n",
    "    print(f\" {'Metric'.ljust(w_name)} │ {col_a_name.ljust(w_a)} │ {col_b_name.ljust(w_b)} \")\n",
    "    print(\"─\" * total)\n",
    "    for name, a, b in rows:\n",
    "        print(f\" {name.ljust(w_name)} │ {a.ljust(w_a)} │ {b.ljust(w_b)} \")\n",
    "    print(\"\")\n",
    "\n",
    "\n",
    "def _cmp(a: float, b: float, *, atol: float, rtol: float) -> int:\n",
    "    \"\"\"\n",
    "    Compare a vs b with tolerances.\n",
    "      -1 if a < b beyond tol\n",
    "       0 if |a-b| <= tol\n",
    "       1 if a > b beyond tol\n",
    "    \"\"\"\n",
    "    tol = max(atol, rtol * abs(b))\n",
    "    if a < b - tol:\n",
    "        return -1\n",
    "    if a > b + tol:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "\n",
    "def _better_text(\n",
    "    label_left: str,\n",
    "    label_right: str,\n",
    "    *,\n",
    "    mae_left: float,\n",
    "    rmse_left: float,\n",
    "    mae_right: float,\n",
    "    rmse_right: float,\n",
    "    atol: float,\n",
    "    rtol: float,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Produce a human-readable verdict that *always* names which is better\n",
    "    when there is a clear winner; otherwise reports 'Comparable' or 'No clear winner'.\n",
    "    \"\"\"\n",
    "    c_mae = _cmp(mae_left, mae_right, atol=atol, rtol=rtol)\n",
    "    c_rmse = _cmp(rmse_left, rmse_right, atol=atol, rtol=rtol)\n",
    "\n",
    "    d_mae = abs(mae_left - mae_right)\n",
    "    d_rmse = abs(rmse_left - rmse_right)\n",
    "\n",
    "    if c_mae == -1 and c_rmse == -1:\n",
    "        # left better\n",
    "        return (\n",
    "            f\"Better: {label_left} \"\n",
    "            f\"(MAE ↓ by {fmt_mev(d_mae)} meV/site, RMSE ↓ by {fmt_mev(d_rmse)} meV/site).\"\n",
    "        )\n",
    "    if c_mae == 1 and c_rmse == 1:\n",
    "        # right better\n",
    "        return (\n",
    "            f\"Better: {label_right} \"\n",
    "            f\"(MAE ↓ by {fmt_mev(d_mae)} meV/site, RMSE ↓ by {fmt_mev(d_rmse)} meV/site).\"\n",
    "        )\n",
    "    if c_mae == 0 and c_rmse == 0:\n",
    "        return (\n",
    "            \"Comparable within tolerance \"\n",
    "            f\"(ΔMAE≈{fmt_mev(d_mae)} meV/site, ΔRMSE≈{fmt_mev(d_rmse)} meV/site).\"\n",
    "        )\n",
    "\n",
    "    # mixed case: one metric favors left, the other favors right\n",
    "    pieces: list[str] = []\n",
    "    if c_mae == -1:\n",
    "        pieces.append(f\"{label_left} has lower MAE by {fmt_mev(d_mae)} meV/site\")\n",
    "    elif c_mae == 1:\n",
    "        pieces.append(f\"{label_right} has lower MAE by {fmt_mev(d_mae)} meV/site\")\n",
    "    if c_rmse == -1:\n",
    "        pieces.append(f\"{label_left} has lower RMSE by {fmt_mev(d_rmse)} meV/site\")\n",
    "    elif c_rmse == 1:\n",
    "        pieces.append(f\"{label_right} has lower RMSE by {fmt_mev(d_rmse)} meV/site\")\n",
    "    return \"No clear winner: \" + \"; \".join(pieces) + \".\"\n",
    "\n",
    "\n",
    "def _predict_per_prim(\n",
    "    ce: ClusterExpansion,\n",
    "    *,\n",
    "    structures: list[Structure],\n",
    "    supercell_diag: tuple[int, int, int],\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Predict energy per-primitive using CE coefficients and features.\n",
    "    \"\"\"\n",
    "    _, X = featurize_structures(\n",
    "        subspace=ce.cluster_subspace,\n",
    "        structures=structures,\n",
    "        supercell_diag=supercell_diag,\n",
    "    )\n",
    "    coefs = np.asarray(getattr(ce, \"coefs\"), dtype=np.float64)\n",
    "    y_pred_per_prim = predict_from_features(X, coefs)\n",
    "    return y_pred_per_prim\n",
    "\n",
    "\n",
    "# ----------------- main comparison -----------------\n",
    "\n",
    "def compare_comp_vs_refined_on_refined_dataset(\n",
    "    refined_ce_key: str,\n",
    "    *,\n",
    "    atol: float = 1e-6,\n",
    "    rtol: float = 1e-8,\n",
    "    verbose: bool = True,\n",
    ") -> dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Cross-compare base composition CE and refined WL CE.\n",
    "\n",
    "    Inputs:\n",
    "      - refined_ce_key: key of a **refined WL CE**.\n",
    "\n",
    "    What it prints (per-site, meV), refined is always the RIGHT column:\n",
    "      1) Base CE evaluated on the *refined* dataset  (left)  vs  Refined CE stored 5-fold CV  (right)\n",
    "      2) Base CE stored 5-fold CV                     (left)  vs  Refined CE evaluated on the *base* dataset (right)\n",
    "\n",
    "    Returns (dict):\n",
    "      - refined_ce_key, base_ce_key, n_prims, sites_per_prim\n",
    "      - base_on_refined_stats_per_site\n",
    "      - refined_cv_stats_per_site\n",
    "      - refined_on_base_stats_per_site\n",
    "      - base_cv_stats_per_site\n",
    "      - design_metrics: {base, refined}\n",
    "    \"\"\"\n",
    "    # --- Load refined CE doc ---\n",
    "    ref_doc = lookup_ce_by_key(refined_ce_key)\n",
    "    if not ref_doc:\n",
    "        raise RuntimeError(f\"No CE found for refined_ce_key={refined_ce_key}\")\n",
    "\n",
    "    sources = cast(Sequence[Mapping[str, Any]], ref_doc[\"sources\"])\n",
    "    if not sources:\n",
    "        raise RuntimeError(\"Refined CE doc has no sources.\")\n",
    "    s0 = sources[0]\n",
    "    s_type = str(s0.get(\"type\", \"\")).lower()\n",
    "    if s_type != \"dopt_sampling_intent\":\n",
    "        raise RuntimeError(f\"Provided CE is not a dopt_sampling_intent CE (source.type={s_type!r}).\")\n",
    "\n",
    "    base_ce_key = cast(str, s0[\"base_ce_key\"])\n",
    "    base_doc = lookup_ce_by_key(base_ce_key)\n",
    "    if not base_doc:\n",
    "        raise RuntimeError(f\"Base (composition) CE not found: {base_ce_key}\")\n",
    "\n",
    "    # --- Basic identity checks (should match in the modern pipeline) ---\n",
    "    r_prototype_spec = PrototypeSpec.from_dict(ref_doc[\"prototype_spec\"])\n",
    "    b_prototype_spec = PrototypeSpec.from_dict(base_doc[\"prototype_spec\"])\n",
    "    if r_prototype_spec != b_prototype_spec:\n",
    "        raise RuntimeError(\"Prototype mismatch between refined CE and base composition CE.\")\n",
    "    \n",
    "    xs, ys, zs = ref_doc[\"supercell_diag\"]\n",
    "    r_sc = (int(xs), int(ys), int(zs))\n",
    "    b_xs, b_ys, b_zs = base_doc[\"supercell_diag\"]\n",
    "    b_sc = (int(b_xs), int(b_ys), int(b_zs))\n",
    "    if r_sc != b_sc:\n",
    "        raise RuntimeError(\"supercell_diag mismatch between refined CE and base composition CE.\")\n",
    "\n",
    "    # --- Per-site scaling (replaceable sites / primitive) ---\n",
    "    n_prims = int(np.prod(np.asarray(r_sc, dtype=int)))\n",
    "    n_sites_const = _n_replace_sites_from_prototype(\n",
    "        prototype_spec=r_prototype_spec,\n",
    "        supercell_diag=r_sc,\n",
    "    )\n",
    "    if n_sites_const % n_prims != 0:\n",
    "        raise RuntimeError(\"sites_per_supercell not divisible by n_prims (prototype/sublattice mismatch).\")\n",
    "    sites_per_prim = n_sites_const // n_prims\n",
    "    scale_site = 1.0 / float(sites_per_prim)\n",
    "\n",
    "    # --- Build refined dataset from refined CE train_refs (structures + energies) ---\n",
    "    dataset = Dataset.from_key(ref_doc[\"dataset_key\"])\n",
    "    structures_refined, energies_eV_super_refined = zip(*[\n",
    "        (r.structure, r.lookup_energy())\n",
    "        for r in dataset.train_refs\n",
    "    ])\n",
    "    y_true_per_prim_refined = (np.asarray(energies_eV_super_refined, dtype=np.float64) / float(n_prims)).astype(np.float64, copy=False)\n",
    "\n",
    "    # --- Evaluate BASE CE on the refined dataset ---\n",
    "    base_ce = ClusterExpansion.from_dict(cast(Mapping[str, Any], base_doc[\"payload\"]))\n",
    "    y_pred_per_prim_base_on_refined = _predict_per_prim(\n",
    "        base_ce,\n",
    "        structures=list(structures_refined),\n",
    "        supercell_diag=r_sc,\n",
    "    )\n",
    "    base_on_refined_stats = compute_stats(\n",
    "        (y_true_per_prim_refined * scale_site).tolist(),\n",
    "        (y_pred_per_prim_base_on_refined * scale_site).tolist(),\n",
    "    )  # per-site\n",
    "\n",
    "    # --- Pull refined CE stored 5-fold CV stats (per-site) ---\n",
    "    ref_stats = cast(Mapping[str, Any], ref_doc[\"stats\"])\n",
    "    ref_cv = cast(Mapping[str, Any], ref_stats[\"five_fold_cv\"])\n",
    "    # also harvest design metrics (stored at training time)\n",
    "    dm_base = cast(Mapping[str, Any] | None, base_doc.get(\"design_metrics\"))\n",
    "    dm_ref = cast(Mapping[str, Any] | None, ref_doc.get(\"design_metrics\"))\n",
    "\n",
    "    # --- Evaluate REFINED CE on the base dataset ---\n",
    "    dataset_base = Dataset.from_key(base_doc[\"dataset_key\"])\n",
    "    structures_base, energies_eV_super_base = zip(*[\n",
    "        (r.structure, r.lookup_energy())\n",
    "        for r in dataset_base.train_refs\n",
    "    ])\n",
    "    y_true_per_prim_base = (np.asarray(energies_eV_super_base, dtype=np.float64) / float(n_prims)).astype(np.float64, copy=False)\n",
    "\n",
    "    refined_ce = ClusterExpansion.from_dict(cast(Mapping[str, Any], ref_doc[\"payload\"]))\n",
    "    y_pred_per_prim_refined_on_base = _predict_per_prim(\n",
    "        refined_ce,\n",
    "        structures=list(structures_base),\n",
    "        supercell_diag=b_sc,  # == r_sc\n",
    "    )\n",
    "    refined_on_base_stats = compute_stats(\n",
    "        (y_true_per_prim_base * scale_site).tolist(),\n",
    "        (y_pred_per_prim_refined_on_base * scale_site).tolist(),\n",
    "    )  # per-site\n",
    "\n",
    "    # --- Base CE stored 5-fold CV (per-site) ---\n",
    "    base_stats = cast(Mapping[str, Any], base_doc[\"stats\"])\n",
    "    base_cv = cast(Mapping[str, Any], base_stats[\"five_fold_cv\"])\n",
    "\n",
    "    # --- Pretty side-by-side printout (refined is ALWAYS right column) ---\n",
    "    if verbose:\n",
    "        print(\"═\" * 86)\n",
    "        print(\" CE Comparison \".center(86, \"═\"))\n",
    "        print(\"═\" * 86)\n",
    "        print(f\"Refined CE key     : {refined_ce_key}\")\n",
    "        print(f\"Base (composition) : {base_ce_key}\")\n",
    "        print(f\"Prototype          : {r_prototype_spec.prototype}\")\n",
    "        print(f\"Supercell diag     : {r_sc}  (n_prims={n_prims}, sites/prim={sites_per_prim})\")\n",
    "        print(\"\")\n",
    "\n",
    "        # 1) Performance: Base CE on refined dataset (left) vs Refined CE stored CV (right)\n",
    "        left_label_1 = \"Base CE (OOS on refined set)\"\n",
    "        right_label_1 = \"Refined CE (5-fold CV, stored)\"\n",
    "        perf_rows_1: list[tuple[str, str, str]] = [\n",
    "            (\"n\",                   str(int(base_on_refined_stats[\"n\"])),                 str(int(ref_cv[\"n\"]))),\n",
    "            (\"MAE (meV/site)\",      fmt_mev(base_on_refined_stats[\"mae_per_site\"]),       fmt_mev(float(ref_cv[\"mae_per_site\"]))),\n",
    "            (\"RMSE (meV/site)\",     fmt_mev(base_on_refined_stats[\"rmse_per_site\"]),      fmt_mev(float(ref_cv[\"rmse_per_site\"]))),\n",
    "            (\"Max|err| (meV/site)\", fmt_mev(base_on_refined_stats[\"max_abs_per_site\"]),   fmt_mev(float(ref_cv[\"max_abs_per_site\"]))),\n",
    "        ]\n",
    "        _print_two_col_table(\n",
    "            title=\"Performance (per-site, meV) — Base CE evaluated on refined dataset  vs  Refined CE stored 5-fold CV\",\n",
    "            col_a_name=left_label_1,\n",
    "            col_b_name=right_label_1,\n",
    "            rows=perf_rows_1,\n",
    "        )\n",
    "\n",
    "        verdict1 = _better_text(\n",
    "            left_label_1, right_label_1,\n",
    "            mae_left=float(base_on_refined_stats[\"mae_per_site\"]),\n",
    "            rmse_left=float(base_on_refined_stats[\"rmse_per_site\"]),\n",
    "            mae_right=float(ref_cv[\"mae_per_site\"]),\n",
    "            rmse_right=float(ref_cv[\"rmse_per_site\"]),\n",
    "            atol=atol, rtol=rtol,\n",
    "        )\n",
    "        print(f\"Verdict A      : {verdict1}\")\n",
    "\n",
    "        # 2) Performance: Base CE stored CV (left) vs Refined CE on base dataset (right)\n",
    "        left_label_2 = \"Base CE (5-fold CV, stored)\"\n",
    "        right_label_2 = \"Refined CE (OOS on base set)\"\n",
    "        perf_rows_2: list[tuple[str, str, str]] = [\n",
    "            (\"n\",                   str(int(base_cv[\"n\"])),                               str(int(refined_on_base_stats[\"n\"]))),\n",
    "            (\"MAE (meV/site)\",      fmt_mev(float(base_cv[\"mae_per_site\"])),              fmt_mev(refined_on_base_stats[\"mae_per_site\"])),\n",
    "            (\"RMSE (meV/site)\",     fmt_mev(float(base_cv[\"rmse_per_site\"])),             fmt_mev(refined_on_base_stats[\"rmse_per_site\"])),\n",
    "            (\"Max|err| (meV/site)\", fmt_mev(float(base_cv[\"max_abs_per_site\"])),          fmt_mev(refined_on_base_stats[\"max_abs_per_site\"])),\n",
    "        ]\n",
    "        _print_two_col_table(\n",
    "            title=\"Performance (per-site, meV) — Base CE stored 5-fold CV  vs  Refined CE evaluated on base dataset\",\n",
    "            col_a_name=left_label_2,\n",
    "            col_b_name=right_label_2,\n",
    "            rows=perf_rows_2,\n",
    "        )\n",
    "\n",
    "        verdict2 = _better_text(\n",
    "            left_label_2, right_label_2,\n",
    "            mae_left=float(base_cv[\"mae_per_site\"]),\n",
    "            rmse_left=float(base_cv[\"rmse_per_site\"]),\n",
    "            mae_right=float(refined_on_base_stats[\"mae_per_site\"]),\n",
    "            rmse_right=float(refined_on_base_stats[\"rmse_per_site\"]),\n",
    "            atol=atol, rtol=rtol,\n",
    "        )\n",
    "        print(f\"Verdict B      : {verdict2}\")\n",
    "        print(\"═\" * 86)\n",
    "\n",
    "    return {\n",
    "        \"refined_ce_key\": refined_ce_key,\n",
    "        \"base_ce_key\": base_ce_key,\n",
    "        \"n_prims\": n_prims,\n",
    "        \"sites_per_prim\": sites_per_prim,\n",
    "        \"base_on_refined_stats_per_site\": base_on_refined_stats,\n",
    "        \"refined_cv_stats_per_site\": ref_cv,\n",
    "        \"refined_on_base_stats_per_site\": refined_on_base_stats,\n",
    "        \"base_cv_stats_per_site\": base_cv,\n",
    "        \"design_metrics\": {\n",
    "            \"base\": dm_base,\n",
    "            \"refined\": dm_ref,\n",
    "        },\n",
    "    }\n",
    "\n",
    "\n",
    "# ---- Example:\n",
    "compare_comp_vs_refined_on_refined_dataset(\"b5d0f390f2ee673499b37fb462f4248b8afa18643b5cd5dd4926c341fda4227e\") # 500\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
