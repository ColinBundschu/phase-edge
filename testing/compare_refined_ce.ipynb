{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae6538b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "════════════════════════════════════════════════════════════════════════\n",
      "═══════════════ CE Validation (per-site metrics in meV) ════════════════\n",
      "════════════════════════════════════════════════════════════════════════\n",
      "CE key        : 781041790a68cc664c64278fed25132d984b3bfbc802d207e41d8626818ff737\n",
      "samples (n)   : 102\n",
      "tolerances    : atol=1e-06, rtol=1e-08\n",
      "------------------------------------------------------------------------\n",
      "In-sample\n",
      "Metric         Stored    Recomputed   Δ (recomp − stored)\n",
      "-------------  --------  ----------   -------------------\n",
      "MAE               0.545      0.545           0.000\n",
      "RMSE              0.691      0.691           0.000\n",
      "Max|err|          1.818      1.818           0.000\n",
      "------------------------------------------------------------------------\n",
      "Stored 5-fold CV\n",
      "Metric         Value\n",
      "-------------  --------\n",
      "n              102\n",
      "MAE               1.312\n",
      "RMSE              1.724\n",
      "Max|err|          5.777\n",
      "------------------------------------------------------------------------\n",
      "Result         : ✅  PASS (in-sample matches stored)\n",
      "════════════════════════════════════════════════════════════════════════\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Any, Mapping, Sequence, cast\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import numpy as np\n",
    "from numpy.typing import NDArray\n",
    "\n",
    "from ase.atoms import Atoms\n",
    "from pymatgen.core import Structure\n",
    "from pymatgen.io.ase import AseAtomsAdaptor\n",
    "\n",
    "# ---- phaseedge imports ----\n",
    "from phaseedge.science.prototypes import PrototypeName\n",
    "from phaseedge.jobs.store_ce_model import lookup_ce_by_key\n",
    "from phaseedge.jobs.decide_relax import lookup_ff_task\n",
    "from phaseedge.science.prototypes import make_prototype\n",
    "from phaseedge.science.random_configs import make_one_snapshot\n",
    "from phaseedge.schemas.mixture import sublattices_from_mixtures, Mixture\n",
    "from phaseedge.jobs.train_ce import (\n",
    "    featurize_structures,\n",
    "    predict_from_features,\n",
    "    compute_stats,\n",
    "    _n_replace_sites_from_prototype,\n",
    ")\n",
    "from phaseedge.utils.keys import (\n",
    "    compute_set_id,\n",
    "    rng_for_index,\n",
    "    occ_key_for_atoms,\n",
    ")\n",
    "from smol.cofe import ClusterExpansion\n",
    "\n",
    "\n",
    "# ----------------- DB helpers -----------------\n",
    "\n",
    "def _lookup_total_energy_eV(\n",
    "    *, set_id: str, occ_key: str, model: str, relax_cell: bool, dtype: str\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Modern schema only: lookup_ff_task returns the inner 'output' document.\n",
    "    Energy is doc['output']['energy'].\n",
    "    \"\"\"\n",
    "    doc = lookup_ff_task(\n",
    "        set_id=set_id, occ_key=occ_key, model=model, relax_cell=relax_cell, dtype=dtype\n",
    "    )\n",
    "    if doc is None:\n",
    "        raise RuntimeError(f\"No FF task output found for set_id={set_id} occ_key={occ_key}\")\n",
    "    try:\n",
    "        return float(doc[\"output\"][\"energy\"])\n",
    "    except Exception as exc:\n",
    "        raise RuntimeError(\n",
    "            f\"FF task output missing energy for set_id={set_id} occ_key={occ_key}\"\n",
    "        ) from exc\n",
    "\n",
    "\n",
    "# ----------------- Composition source parsing -----------------\n",
    "\n",
    "def _gather_composition_mixtures(sources: Sequence[Mapping[str, Any]]) -> list[Mixture]:\n",
    "    \"\"\"Modern, normalized sources → list[Mixture].\"\"\"\n",
    "    mixes: list[Mixture] = []\n",
    "    for s in sources:\n",
    "        if str(s.get(\"type\", \"\")).lower() != \"composition\":\n",
    "            continue\n",
    "        for m in s.get(\"mixtures\", []):\n",
    "            mixes.append(Mixture.from_dict({\n",
    "                \"composition_map\": dict(m[\"composition_map\"]),\n",
    "                \"K\": int(m[\"K\"]),\n",
    "                \"seed\": int(m[\"seed\"]),\n",
    "            }))\n",
    "    return mixes\n",
    "\n",
    "\n",
    "# ----------------- Snapshot reconstruction -----------------\n",
    "\n",
    "def _build_occ_to_structure_for_set(\n",
    "    *,\n",
    "    set_id: str,\n",
    "    mixture: Mixture,\n",
    "    conv_cell: Atoms,\n",
    "    supercell_diag: tuple[int, int, int],\n",
    ") -> dict[str, Structure]:\n",
    "    \"\"\"\n",
    "    Generate exactly K snapshots for this set (deterministic RNG),\n",
    "    and return a map occ_key -> unrelaxed Structure.\n",
    "    \"\"\"\n",
    "    occ2struct: dict[str, Structure] = {}\n",
    "    for idx in range(mixture.K):\n",
    "        rng = rng_for_index(set_id, idx)\n",
    "        snap: Atoms = make_one_snapshot(\n",
    "            conv_cell=conv_cell,\n",
    "            supercell_diag=supercell_diag,\n",
    "            composition_map=mixture.composition_map,\n",
    "            rng=rng,\n",
    "        )\n",
    "        key = occ_key_for_atoms(snap)\n",
    "        occ2struct[key] = cast(Structure, AseAtomsAdaptor.get_structure(snap))\n",
    "    return occ2struct\n",
    "\n",
    "\n",
    "# ----------------- Pretty summary -----------------\n",
    "\n",
    "def _fmt_mev(x: float | str) -> str:\n",
    "    if isinstance(x, str):\n",
    "        return x\n",
    "    return f\"{1e3 * float(x):.3f}\"\n",
    "\n",
    "def _print_summary(\n",
    "    *,\n",
    "    ce_key: str,\n",
    "    n: int,\n",
    "    stored_in: Mapping[str, Any],\n",
    "    recomputed_in: Mapping[str, Any],\n",
    "    stored_cv: Mapping[str, Any] | None,\n",
    "    atol: float,\n",
    "    rtol: float,\n",
    "    ok: bool,\n",
    ") -> None:\n",
    "    s_mae, s_rmse, s_max = (\n",
    "        float(stored_in[\"mae_per_site\"]),\n",
    "        float(stored_in[\"rmse_per_site\"]),\n",
    "        float(stored_in[\"max_abs_per_site\"]),\n",
    "    )\n",
    "    r_mae, r_rmse, r_max = (\n",
    "        float(recomputed_in[\"mae_per_site\"]),\n",
    "        float(recomputed_in[\"rmse_per_site\"]),\n",
    "        float(recomputed_in[\"max_abs_per_site\"]),\n",
    "    )\n",
    "\n",
    "    print(\"═\" * 72)\n",
    "    print(f\" CE Validation (per-site metrics in meV) \".center(72, \"═\"))\n",
    "    print(\"═\" * 72)\n",
    "    print(f\"CE key        : {ce_key}\")\n",
    "    print(f\"samples (n)   : {n}\")\n",
    "    print(f\"tolerances    : atol={atol:g}, rtol={rtol:g}\")\n",
    "    print(\"-\" * 72)\n",
    "    print(\"In-sample\")\n",
    "    print(\"Metric         Stored    Recomputed   Δ (recomp − stored)\")\n",
    "    print(\"-------------  --------  ----------   -------------------\")\n",
    "    print(f\"MAE            {_fmt_mev(s_mae):>8}   {_fmt_mev(r_mae):>8}        {_fmt_mev(r_mae - s_mae):>8}\")\n",
    "    print(f\"RMSE           {_fmt_mev(s_rmse):>8}   {_fmt_mev(r_rmse):>8}        {_fmt_mev(r_rmse - s_rmse):>8}\")\n",
    "    print(f\"Max|err|       {_fmt_mev(s_max):>8}   {_fmt_mev(r_max):>8}        {_fmt_mev(r_max - s_max):>8}\")\n",
    "    print(\"-\" * 72)\n",
    "\n",
    "    if stored_cv and all(k in stored_cv for k in (\"n\", \"mae_per_site\", \"rmse_per_site\", \"max_abs_per_site\")):\n",
    "        cv_n = int(stored_cv[\"n\"])\n",
    "        cv_mae = float(stored_cv[\"mae_per_site\"])\n",
    "        cv_rmse = float(stored_cv[\"rmse_per_site\"])\n",
    "        cv_max = float(stored_cv[\"max_abs_per_site\"])\n",
    "        print(\"Stored 5-fold CV\")\n",
    "        print(\"Metric         Value\")\n",
    "        print(\"-------------  --------\")\n",
    "        print(f\"n              {cv_n}\")\n",
    "        print(f\"MAE            {_fmt_mev(cv_mae):>8}\")\n",
    "        print(f\"RMSE           {_fmt_mev(cv_rmse):>8}\")\n",
    "        print(f\"Max|err|       {_fmt_mev(cv_max):>8}\")\n",
    "        print(\"-\" * 72)\n",
    "    else:\n",
    "        print(\"Stored 5-fold CV: <not available>\")\n",
    "        print(\"-\" * 72)\n",
    "\n",
    "    print(\"Result         : \" + (\"✅  PASS (in-sample matches stored)\"\n",
    "                              if ok else \"❌  FAIL (in-sample mismatch)\"))\n",
    "    print(\"═\" * 72)\n",
    "\n",
    "\n",
    "# ----------------- Main verifier (in-sample only) -----------------\n",
    "\n",
    "def verify_ce_in_sample(\n",
    "    ce_key: str,\n",
    "    *,\n",
    "    atol: float = 1e-6,\n",
    "    rtol: float = 1e-8,\n",
    "    verbose: bool = True,\n",
    ") -> bool:\n",
    "    \"\"\"\n",
    "    Recompute and validate **in-sample** per-site stats (composition CE only).\n",
    "\n",
    "    PASS/FAIL is based solely on the top-level 'in_sample' stats.\n",
    "    \"\"\"\n",
    "    # ---- Load document and assume modern schema ----\n",
    "    doc = lookup_ce_by_key(ce_key)\n",
    "    if not doc:\n",
    "        raise RuntimeError(f\"No CE found for ce_key={ce_key}\")\n",
    "\n",
    "    stats_stored = cast(Mapping[str, Any], doc[\"stats\"])\n",
    "    in_sample_stored = cast(Mapping[str, Any], stats_stored[\"in_sample\"])\n",
    "    stored_cv = cast(Mapping[str, Any] | None, stats_stored.get(\"five_fold_cv\"))\n",
    "\n",
    "    sources = cast(Sequence[Mapping[str, Any]], doc[\"sources\"])\n",
    "    mixtures = _gather_composition_mixtures(sources)\n",
    "    if not mixtures:\n",
    "        raise RuntimeError(\"Expected 'composition' sources in modern schema.\")\n",
    "\n",
    "    prototype = PrototypeName(doc[\"prototype\"])\n",
    "    proto_params = cast(Mapping[str, Any], doc[\"prototype_params\"])\n",
    "    sx, sy, sz = (int(x) for x in doc[\"supercell_diag\"])\n",
    "    supercell_diag = (sx, sy, sz)\n",
    "    model = cast(str, doc[\"model\"])\n",
    "    relax_cell = bool(doc[\"relax_cell\"])\n",
    "    dtype = cast(str, doc[\"dtype\"])\n",
    "    train_refs = cast(Sequence[Mapping[str, Any]], doc[\"train_refs\"])\n",
    "\n",
    "    # ---- Build index of occ_keys per set_id from train_refs (strict) ----\n",
    "    refs_by_sid: dict[str, list[str]] = defaultdict(list)\n",
    "    for r in train_refs:\n",
    "        refs_by_sid[str(r[\"set_id\"])].append(str(r[\"occ_key\"]))\n",
    "\n",
    "    # Strict coverage check: computed set_ids from mixtures must equal refs_by_sid keys\n",
    "    computed_sids = {\n",
    "        compute_set_id(\n",
    "            prototype=prototype,\n",
    "            prototype_params=proto_params,\n",
    "            supercell_diag=supercell_diag,\n",
    "            composition_map=mix.composition_map,\n",
    "            seed=mix.seed,\n",
    "        )\n",
    "        for mix in mixtures\n",
    "    }\n",
    "    if set(refs_by_sid.keys()) != computed_sids:\n",
    "        missing_in_refs = sorted(computed_sids - set(refs_by_sid.keys()))\n",
    "        missing_in_mixes = sorted(set(refs_by_sid.keys()) - computed_sids)\n",
    "        raise RuntimeError(\n",
    "            \"Mismatch between mixture-derived set_ids and train_refs set_ids.\\n\"\n",
    "            f\"  Missing in train_refs: {missing_in_refs}\\n\"\n",
    "            f\"  Missing in mixtures  : {missing_in_mixes}\"\n",
    "        )\n",
    "\n",
    "    # ---- Prepare prototype conventional cell (ASE Atoms) ----\n",
    "    conv_cell: Atoms = make_prototype(prototype, **dict(proto_params))\n",
    "\n",
    "    # ---- Reconstruct training structures & energies in deterministic order ----\n",
    "    structures: list[Structure] = []\n",
    "    energies_supercell: list[float] = []\n",
    "    # Iterate mixtures → stable SID order; then occ_keys in recorded order\n",
    "    for mix in mixtures:\n",
    "        sid = compute_set_id(\n",
    "            prototype=prototype,\n",
    "            prototype_params=proto_params,\n",
    "            supercell_diag=supercell_diag,\n",
    "            composition_map=mix.composition_map,\n",
    "            seed=mix.seed,\n",
    "        )\n",
    "        occ_to_struct = _build_occ_to_structure_for_set(\n",
    "            set_id=sid,\n",
    "            mixture=mix,\n",
    "            conv_cell=conv_cell,\n",
    "            supercell_diag=supercell_diag,\n",
    "        )\n",
    "        for occ_key in refs_by_sid[sid]:\n",
    "            s = occ_to_struct.get(occ_key)\n",
    "            if s is None:\n",
    "                raise RuntimeError(f\"Could not reconstruct snapshot for set_id={sid} occ_key={occ_key}\")\n",
    "            structures.append(s)\n",
    "            energies_supercell.append(\n",
    "                _lookup_total_energy_eV(set_id=sid, occ_key=occ_key, model=model, relax_cell=relax_cell, dtype=dtype)\n",
    "            )\n",
    "\n",
    "    if len(structures) != len(train_refs):\n",
    "        raise RuntimeError(\"Mismatch in number of reconstructed structures vs. train_refs.\")\n",
    "\n",
    "    # ---- Rehydrate CE and build features ----\n",
    "    ce = ClusterExpansion.from_dict(cast(Mapping[str, Any], doc[\"payload\"]))\n",
    "    subspace = ce.cluster_subspace\n",
    "\n",
    "    _, X = featurize_structures(\n",
    "        subspace=subspace,\n",
    "        structures=cast(Sequence[Structure], structures),\n",
    "        supercell_diag=supercell_diag,\n",
    "    )\n",
    "\n",
    "    # Targets are per primitive/conventional cell\n",
    "    n_prims = int(np.prod(np.asarray(supercell_diag, dtype=int)))\n",
    "    y_true_per_prim: NDArray[np.float64] = (\n",
    "        np.asarray(energies_supercell, dtype=np.float64) / float(n_prims)\n",
    "    ).astype(np.float64, copy=False)\n",
    "\n",
    "    # Per-site scaling\n",
    "    sites_per_supercell = _n_replace_sites_from_prototype(\n",
    "        prototype=prototype,\n",
    "        prototype_params=proto_params,\n",
    "        supercell_diag=supercell_diag,\n",
    "        sublattices=sublattices_from_mixtures(mixtures),\n",
    "    )\n",
    "    if sites_per_supercell % n_prims != 0:\n",
    "        raise RuntimeError(\"sites_per_supercell is not divisible by n_prims.\")\n",
    "    sites_per_prim = sites_per_supercell // n_prims\n",
    "    scale_site = 1.0 / float(sites_per_prim)\n",
    "\n",
    "    # ---- In-sample prediction using stored ECIs ----\n",
    "    coefs = np.asarray(getattr(ce, \"coefs\"), dtype=np.float64)\n",
    "    y_pred_per_prim_ins = predict_from_features(X, coefs)\n",
    "\n",
    "    in_sample_recomputed = compute_stats(\n",
    "        (y_true_per_prim * scale_site).tolist(),\n",
    "        (y_pred_per_prim_ins * scale_site).tolist(),\n",
    "    )\n",
    "\n",
    "    # ---- Compare + summarize ----\n",
    "    ok = (\n",
    "        int(in_sample_recomputed[\"n\"]) == int(in_sample_stored[\"n\"])\n",
    "        and math.isclose(float(in_sample_recomputed[\"mae_per_site\"]),  float(in_sample_stored[\"mae_per_site\"]),  rel_tol=rtol, abs_tol=atol)\n",
    "        and math.isclose(float(in_sample_recomputed[\"rmse_per_site\"]), float(in_sample_stored[\"rmse_per_site\"]), rel_tol=rtol, abs_tol=atol)\n",
    "        and math.isclose(float(in_sample_recomputed[\"max_abs_per_site\"]), float(in_sample_stored[\"max_abs_per_site\"]), rel_tol=rtol, abs_tol=atol)\n",
    "    )\n",
    "\n",
    "    if verbose:\n",
    "        _print_summary(\n",
    "            ce_key=ce_key,\n",
    "            n=int(in_sample_recomputed[\"n\"]),\n",
    "            stored_in=in_sample_stored,\n",
    "            recomputed_in=in_sample_recomputed,\n",
    "            stored_cv=stored_cv,\n",
    "            atol=atol, rtol=rtol, ok=ok,\n",
    "        )\n",
    "\n",
    "    return ok\n",
    "\n",
    "\n",
    "# ---- Example usage:\n",
    "verify_ce_in_sample(\"781041790a68cc664c64278fed25132d984b3bfbc802d207e41d8626818ff737\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5880a462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "════════════════════════════════════════════════════════════════════════\n",
      "═══════════════ CE Validation (per-site metrics in meV) ════════════════\n",
      "════════════════════════════════════════════════════════════════════════\n",
      "CE key        : 76195c946ffef01b43a45fbccfb192c96d55011b69a54b0ccc2d6ff9f6f59bba\n",
      "samples (n)   : 102\n",
      "tolerances    : atol=1e-06, rtol=1e-08\n",
      "------------------------------------------------------------------------\n",
      "In-sample\n",
      "Metric         Stored    Recomputed   Δ (recomp − stored)\n",
      "-------------  --------  ----------   -------------------\n",
      "MAE               0.478      0.478           0.000\n",
      "RMSE              0.601      0.601           0.000\n",
      "Max|err|          1.645      1.645           0.000\n",
      "------------------------------------------------------------------------\n",
      "Stored 5-fold CV\n",
      "Metric         Value\n",
      "-------------  --------\n",
      "n              102\n",
      "MAE               1.206\n",
      "RMSE              1.577\n",
      "Max|err|          4.511\n",
      "------------------------------------------------------------------------\n",
      "Result         : ✅  PASS (in-sample matches stored)\n",
      "════════════════════════════════════════════════════════════════════════\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Any, Mapping, Sequence, cast\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import numpy as np\n",
    "from numpy.typing import NDArray\n",
    "\n",
    "from ase.atoms import Atoms\n",
    "from pymatgen.core import Structure\n",
    "from pymatgen.io.ase import AseAtomsAdaptor\n",
    "\n",
    "# ---- phaseedge imports ----\n",
    "from phaseedge.science.prototypes import PrototypeName\n",
    "from phaseedge.jobs.store_ce_model import lookup_ce_by_key\n",
    "from phaseedge.jobs.decide_relax import lookup_ff_task\n",
    "from phaseedge.science.prototypes import make_prototype\n",
    "from phaseedge.science.random_configs import make_one_snapshot\n",
    "from phaseedge.schemas.mixture import sublattices_from_mixtures, Mixture\n",
    "from phaseedge.jobs.train_ce import (\n",
    "    featurize_structures,\n",
    "    predict_from_features,\n",
    "    compute_stats,\n",
    "    _n_replace_sites_from_prototype,\n",
    ")\n",
    "from phaseedge.utils.keys import (\n",
    "    compute_set_id,\n",
    "    rng_for_index,\n",
    "    occ_key_for_atoms,\n",
    ")\n",
    "from phaseedge.utils.rehydrators import rehydrate_ensemble_by_ce_key\n",
    "from smol.cofe import ClusterExpansion\n",
    "\n",
    "\n",
    "# ----------------- DB helpers -----------------\n",
    "\n",
    "def _lookup_total_energy_eV(\n",
    "    *, set_id: str, occ_key: str, model: str, relax_cell: bool, dtype: str\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Modern schema only: lookup_ff_task returns the inner 'output' document.\n",
    "    Energy is doc['output']['energy'].\n",
    "    \"\"\"\n",
    "    doc = lookup_ff_task(\n",
    "        set_id=set_id, occ_key=occ_key, model=model, relax_cell=relax_cell, dtype=dtype\n",
    "    )\n",
    "    if doc is None:\n",
    "        raise RuntimeError(f\"No FF task output found for set_id={set_id} occ_key={occ_key}\")\n",
    "    try:\n",
    "        return float(doc[\"output\"][\"energy\"])\n",
    "    except Exception as exc:\n",
    "        raise RuntimeError(\n",
    "            f\"FF task output missing energy for set_id={set_id} occ_key={occ_key}\"\n",
    "        ) from exc\n",
    "\n",
    "\n",
    "# ----------------- Source parsing -----------------\n",
    "\n",
    "def _gather_composition_mixtures(sources: Sequence[Mapping[str, Any]]) -> list[Mixture]:\n",
    "    \"\"\"Modern, normalized sources → list[Mixture].\"\"\"\n",
    "    mixes: list[Mixture] = []\n",
    "    for s in sources:\n",
    "        if str(s.get(\"type\", \"\")).lower() != \"composition\":\n",
    "            continue\n",
    "        for m in s.get(\"mixtures\", []):\n",
    "            mixes.append(Mixture.from_dict({\n",
    "                \"composition_map\": dict(m[\"composition_map\"]),\n",
    "                \"K\": int(m[\"K\"]),\n",
    "                \"seed\": int(m[\"seed\"]),\n",
    "            }))\n",
    "    return mixes\n",
    "\n",
    "\n",
    "def _source_kind(sources: Sequence[Mapping[str, Any]]) -> str:\n",
    "    \"\"\"\n",
    "    Return 'composition' or 'wl_refined_intent' based on modern source types.\n",
    "    Raises if unsupported or ambiguous.\n",
    "    \"\"\"\n",
    "    types = [str(s.get(\"type\", \"\")).lower() for s in sources]\n",
    "    if any(t == \"wl_refined_intent\" for t in types):\n",
    "        return \"wl_refined_intent\"\n",
    "    if any(t == \"composition\" for t in types):\n",
    "        return \"composition\"\n",
    "    raise RuntimeError(f\"Unsupported sources: {types}\")\n",
    "\n",
    "\n",
    "def _get_base_ce_key_for_refined(sources: Sequence[Mapping[str, Any]]) -> str:\n",
    "    for s in sources:\n",
    "        if str(s.get(\"type\", \"\")).lower() == \"wl_refined_intent\":\n",
    "            b = s.get(\"base_ce_key\")\n",
    "            if not isinstance(b, str) or not b:\n",
    "                raise RuntimeError(\"wl_refined_intent source missing valid 'base_ce_key'.\")\n",
    "            return b\n",
    "    raise RuntimeError(\"wl_refined_intent source not found.\")\n",
    "\n",
    "\n",
    "# ----------------- Snapshot reconstruction (composition CEs) -----------------\n",
    "\n",
    "def _build_occ_to_structure_for_set(\n",
    "    *,\n",
    "    set_id: str,\n",
    "    mixture: Mixture,\n",
    "    conv_cell: Atoms,\n",
    "    supercell_diag: tuple[int, int, int],\n",
    ") -> dict[str, Structure]:\n",
    "    \"\"\"\n",
    "    Generate exactly K snapshots for this set (deterministic RNG),\n",
    "    and return a map occ_key -> unrelaxed Structure.\n",
    "    \"\"\"\n",
    "    occ2struct: dict[str, Structure] = {}\n",
    "    for idx in range(mixture.K):\n",
    "        rng = rng_for_index(set_id, idx)\n",
    "        snap: Atoms = make_one_snapshot(\n",
    "            conv_cell=conv_cell,\n",
    "            supercell_diag=supercell_diag,\n",
    "            composition_map=mixture.composition_map,\n",
    "            rng=rng,\n",
    "        )\n",
    "        key = occ_key_for_atoms(snap)\n",
    "        occ2struct[key] = cast(Structure, AseAtomsAdaptor.get_structure(snap))\n",
    "    return occ2struct\n",
    "\n",
    "\n",
    "# ----------------- Structure extraction (refined WL CEs) -----------------\n",
    "\n",
    "def _structure_from_ff_doc(\n",
    "    doc: Mapping[str, Any],\n",
    "    *,\n",
    "    base_ce_key: str | None = None,\n",
    ") -> Structure:\n",
    "    \"\"\"\n",
    "    Modern-only structure extraction priority:\n",
    "    1) doc['structure'] as pymatgen dict\n",
    "    2) doc['output']['structure'] as pymatgen dict\n",
    "    3) doc['occ'] with base CE ensemble → reconstruct\n",
    "    \"\"\"\n",
    "    s_top = doc.get(\"structure\")\n",
    "    if isinstance(s_top, Mapping) and s_top.get(\"@class\") == \"Structure\":\n",
    "        return Structure.from_dict(cast(Mapping[str, Any], s_top))\n",
    "\n",
    "    out = doc.get(\"output\", {})\n",
    "    if isinstance(out, Mapping):\n",
    "        s_out = out.get(\"structure\")\n",
    "        if isinstance(s_out, Mapping) and s_out.get(\"@class\") == \"Structure\":\n",
    "            return Structure.from_dict(cast(Mapping[str, Any], s_out))\n",
    "\n",
    "    occ = doc.get(\"occ\")\n",
    "    if isinstance(occ, list) and all(isinstance(x, (int, np.integer)) for x in occ):\n",
    "        if not base_ce_key:\n",
    "            raise RuntimeError(\"FF doc contains 'occ' but no base_ce_key was provided for reconstruction.\")\n",
    "        ens = rehydrate_ensemble_by_ce_key(base_ce_key)\n",
    "        occ_arr = np.asarray([int(x) for x in occ], dtype=np.int32)\n",
    "        st = ens.processor.structure_from_occupancy(occ_arr)  # returns pymatgen Structure (modern smol)\n",
    "        if isinstance(st, Structure):\n",
    "            return st\n",
    "        if isinstance(st, Atoms):\n",
    "            return cast(Structure, AseAtomsAdaptor.get_structure(st))\n",
    "        raise RuntimeError(\"Unknown structure type returned by ensemble processor.\")\n",
    "\n",
    "    raise RuntimeError(\"Could not extract structure from FF doc (no structure/occ present).\")\n",
    "\n",
    "\n",
    "# ----------------- Pretty summary -----------------\n",
    "\n",
    "def _fmt_mev(x: float | str) -> str:\n",
    "    if isinstance(x, str):\n",
    "        return x\n",
    "    return f\"{1e3 * float(x):.3f}\"\n",
    "\n",
    "def _print_summary(\n",
    "    *,\n",
    "    ce_key: str,\n",
    "    n: int,\n",
    "    stored_in: Mapping[str, Any],\n",
    "    recomputed_in: Mapping[str, Any],\n",
    "    stored_cv: Mapping[str, Any] | None,\n",
    "    atol: float,\n",
    "    rtol: float,\n",
    "    ok: bool,\n",
    ") -> None:\n",
    "    s_mae, s_rmse, s_max = (\n",
    "        float(stored_in[\"mae_per_site\"]),\n",
    "        float(stored_in[\"rmse_per_site\"]),\n",
    "        float(stored_in[\"max_abs_per_site\"]),\n",
    "    )\n",
    "    r_mae, r_rmse, r_max = (\n",
    "        float(recomputed_in[\"mae_per_site\"]),\n",
    "        float(recomputed_in[\"rmse_per_site\"]),\n",
    "        float(recomputed_in[\"max_abs_per_site\"]),\n",
    "    )\n",
    "\n",
    "    print(\"═\" * 72)\n",
    "    print(f\" CE Validation (per-site metrics in meV) \".center(72, \"═\"))\n",
    "    print(\"═\" * 72)\n",
    "    print(f\"CE key        : {ce_key}\")\n",
    "    print(f\"samples (n)   : {n}\")\n",
    "    print(f\"tolerances    : atol={atol:g}, rtol={rtol:g}\")\n",
    "    print(\"-\" * 72)\n",
    "    print(\"In-sample\")\n",
    "    print(\"Metric         Stored    Recomputed   Δ (recomp − stored)\")\n",
    "    print(\"-------------  --------  ----------   -------------------\")\n",
    "    print(f\"MAE            {_fmt_mev(s_mae):>8}   {_fmt_mev(r_mae):>8}        {_fmt_mev(r_mae - s_mae):>8}\")\n",
    "    print(f\"RMSE           {_fmt_mev(s_rmse):>8}   {_fmt_mev(r_rmse):>8}        {_fmt_mev(r_rmse - s_rmse):>8}\")\n",
    "    print(f\"Max|err|       {_fmt_mev(s_max):>8}   {_fmt_mev(r_max):>8}        {_fmt_mev(r_max - s_max):>8}\")\n",
    "    print(\"-\" * 72)\n",
    "\n",
    "    if stored_cv and all(k in stored_cv for k in (\"n\", \"mae_per_site\", \"rmse_per_site\", \"max_abs_per_site\")):\n",
    "        cv_n = int(stored_cv[\"n\"])\n",
    "        cv_mae = float(stored_cv[\"mae_per_site\"])\n",
    "        cv_rmse = float(stored_cv[\"rmse_per_site\"])\n",
    "        cv_max = float(stored_cv[\"max_abs_per_site\"])\n",
    "        print(\"Stored 5-fold CV\")\n",
    "        print(\"Metric         Value\")\n",
    "        print(\"-------------  --------\")\n",
    "        print(f\"n              {cv_n}\")\n",
    "        print(f\"MAE            {_fmt_mev(cv_mae):>8}\")\n",
    "        print(f\"RMSE           {_fmt_mev(cv_rmse):>8}\")\n",
    "        print(f\"Max|err|       {_fmt_mev(cv_max):>8}\")\n",
    "        print(\"-\" * 72)\n",
    "    else:\n",
    "        print(\"Stored 5-fold CV: <not available>\")\n",
    "        print(\"-\" * 72)\n",
    "\n",
    "    print(\"Result         : \" + (\"✅  PASS (in-sample matches stored)\"\n",
    "                              if ok else \"❌  FAIL (in-sample mismatch)\"))\n",
    "    print(\"═\" * 72)\n",
    "\n",
    "\n",
    "# ----------------- Main verifier (in-sample only) -----------------\n",
    "\n",
    "def verify_ce_in_sample(\n",
    "    ce_key: str,\n",
    "    *,\n",
    "    atol: float = 1e-6,\n",
    "    rtol: float = 1e-8,\n",
    "    verbose: bool = True,\n",
    ") -> bool:\n",
    "    \"\"\"\n",
    "    Recompute and validate **in-sample** per-site stats for:\n",
    "      - composition CEs (ensure_ce_from_mixtures)\n",
    "      - refined WL CEs (ensure_ce_from_refined_wl)\n",
    "    Modern schema only. PASS/FAIL is based solely on top-level 'in_sample' stats.\n",
    "    \"\"\"\n",
    "    # ---- Load document and assume modern schema ----\n",
    "    doc = lookup_ce_by_key(ce_key)\n",
    "    if not doc:\n",
    "        raise RuntimeError(f\"No CE found for ce_key={ce_key}\")\n",
    "\n",
    "    stats_stored = cast(Mapping[str, Any], doc[\"stats\"])\n",
    "    in_sample_stored = cast(Mapping[str, Any], stats_stored[\"in_sample\"])\n",
    "    stored_cv = cast(Mapping[str, Any] | None, stats_stored.get(\"five_fold_cv\"))\n",
    "\n",
    "    sources = cast(Sequence[Mapping[str, Any]], doc[\"sources\"])\n",
    "    kind = _source_kind(sources)\n",
    "\n",
    "    prototype = PrototypeName(doc[\"prototype\"])\n",
    "    proto_params = cast(Mapping[str, Any], doc[\"prototype_params\"])\n",
    "    sx, sy, sz = (int(x) for x in doc[\"supercell_diag\"])\n",
    "    supercell_diag = (sx, sy, sz)\n",
    "    model = cast(str, doc[\"model\"])\n",
    "    relax_cell = bool(doc[\"relax_cell\"])\n",
    "    dtype = cast(str, doc[\"dtype\"])\n",
    "    train_refs = cast(Sequence[Mapping[str, Any]], doc[\"train_refs\"])\n",
    "\n",
    "    # ---- Determine sublattices (needed for per-site scaling) ----\n",
    "    if kind == \"composition\":\n",
    "        mixtures = _gather_composition_mixtures(sources)\n",
    "        if not mixtures:\n",
    "            raise RuntimeError(\"Expected 'composition' mixtures in sources.\")\n",
    "        sublattices = sublattices_from_mixtures(mixtures)\n",
    "    elif kind == \"wl_refined_intent\":\n",
    "        base_ce_key = _get_base_ce_key_for_refined(sources)\n",
    "        base_doc = lookup_ce_by_key(base_ce_key)\n",
    "        if not base_doc:\n",
    "            raise RuntimeError(f\"Base CE not found for base_ce_key={base_ce_key}\")\n",
    "        base_mixtures = _gather_composition_mixtures(cast(Sequence[Mapping[str, Any]], base_doc[\"sources\"]))\n",
    "        if not base_mixtures:\n",
    "            raise RuntimeError(\"Base CE sources did not contain 'composition' mixtures.\")\n",
    "        sublattices = sublattices_from_mixtures(base_mixtures)\n",
    "    else:\n",
    "        raise RuntimeError(f\"Unhandled source kind: {kind}\")\n",
    "\n",
    "    # ---- Prepare prototype conventional cell (ASE Atoms) for composition path ----\n",
    "    conv_cell: Atoms | None = None\n",
    "    if kind == \"composition\":\n",
    "        conv_cell = make_prototype(prototype, **dict(proto_params))\n",
    "\n",
    "    # ---- Reconstruct training structures & energies in deterministic order ----\n",
    "    structures: list[Structure] = []\n",
    "    energies_supercell: list[float] = []\n",
    "\n",
    "    if kind == \"composition\":\n",
    "        # Build occ->structure cache per set_id\n",
    "        mixtures = _gather_composition_mixtures(sources)\n",
    "        sid_for_mix: dict[Mixture, str] = {}\n",
    "        for mix in mixtures:\n",
    "            sid = compute_set_id(\n",
    "                prototype=prototype,\n",
    "                prototype_params=proto_params,\n",
    "                supercell_diag=supercell_diag,\n",
    "                composition_map=mix.composition_map,\n",
    "                seed=mix.seed,\n",
    "            )\n",
    "            sid_for_mix[mix] = sid\n",
    "\n",
    "        # Strict coverage check\n",
    "        refs_by_sid: dict[str, list[str]] = defaultdict(list)\n",
    "        for r in train_refs:\n",
    "            refs_by_sid[str(r[\"set_id\"])].append(str(r[\"occ_key\"]))\n",
    "        computed_sids = set(sid_for_mix.values())\n",
    "        if set(refs_by_sid.keys()) != computed_sids:\n",
    "            missing_in_refs = sorted(computed_sids - set(refs_by_sid.keys()))\n",
    "            missing_in_mixes = sorted(set(refs_by_sid.keys()) - computed_sids)\n",
    "            raise RuntimeError(\n",
    "                \"Mismatch between mixture-derived set_ids and train_refs set_ids.\\n\"\n",
    "                f\"  Missing in train_refs: {missing_in_refs}\\n\"\n",
    "                f\"  Missing in mixtures  : {missing_in_mixes}\"\n",
    "            )\n",
    "\n",
    "        # Cache structures per set\n",
    "        occ_struct_cache: dict[str, dict[str, Structure]] = {}\n",
    "        assert conv_cell is not None\n",
    "        for mix, sid in sid_for_mix.items():\n",
    "            occ_struct_cache[sid] = _build_occ_to_structure_for_set(\n",
    "                set_id=sid,\n",
    "                mixture=mix,\n",
    "                conv_cell=conv_cell,\n",
    "                supercell_diag=supercell_diag,\n",
    "            )\n",
    "\n",
    "        # Iterate train_refs in their stored order\n",
    "        for r in train_refs:\n",
    "            sid = str(r[\"set_id\"])\n",
    "            ok = str(r[\"occ_key\"])\n",
    "            s = occ_struct_cache[sid].get(ok)\n",
    "            if s is None:\n",
    "                raise RuntimeError(f\"Could not reconstruct snapshot for set_id={sid} occ_key={ok}\")\n",
    "            structures.append(s)\n",
    "            energies_supercell.append(\n",
    "                _lookup_total_energy_eV(set_id=sid, occ_key=ok, model=model, relax_cell=relax_cell, dtype=dtype)\n",
    "            )\n",
    "\n",
    "    else:  # wl_refined_intent\n",
    "        base_ce_key = _get_base_ce_key_for_refined(sources)\n",
    "        # Iterate train_refs in stored order; structures sourced from FF doc (structure or occ via base CE)\n",
    "        for r in train_refs:\n",
    "            sid = str(r[\"set_id\"])\n",
    "            ok = str(r[\"occ_key\"])\n",
    "            ff_doc = lookup_ff_task(set_id=sid, occ_key=ok, model=model, relax_cell=relax_cell, dtype=dtype)\n",
    "            if ff_doc is None:\n",
    "                raise RuntimeError(f\"Missing FF task for set_id={sid} occ_key={ok}\")\n",
    "            structures.append(_structure_from_ff_doc(ff_doc, base_ce_key=base_ce_key))\n",
    "            energies_supercell.append(float(ff_doc[\"output\"][\"energy\"]))\n",
    "\n",
    "    if len(structures) != len(train_refs):\n",
    "        raise RuntimeError(\"Mismatch in number of reconstructed structures vs. train_refs.\")\n",
    "\n",
    "    # ---- Rehydrate CE and build features ----\n",
    "    ce = ClusterExpansion.from_dict(cast(Mapping[str, Any], doc[\"payload\"]))\n",
    "    subspace = ce.cluster_subspace\n",
    "\n",
    "    _, X = featurize_structures(\n",
    "        subspace=subspace,\n",
    "        structures=cast(Sequence[Structure], structures),\n",
    "        supercell_diag=supercell_diag,\n",
    "    )\n",
    "\n",
    "    # Targets are per primitive/conventional cell\n",
    "    n_prims = int(np.prod(np.asarray(supercell_diag, dtype=int)))\n",
    "    y_true_per_prim: NDArray[np.float64] = (\n",
    "        np.asarray(energies_supercell, dtype=np.float64) / float(n_prims)\n",
    "    ).astype(np.float64, copy=False)\n",
    "\n",
    "    # Per-site scaling\n",
    "    sites_per_supercell = _n_replace_sites_from_prototype(\n",
    "        prototype=prototype,\n",
    "        prototype_params=proto_params,\n",
    "        supercell_diag=supercell_diag,\n",
    "        sublattices=sublattices,\n",
    "    )\n",
    "    if sites_per_supercell % n_prims != 0:\n",
    "        raise RuntimeError(\"sites_per_supercell is not divisible by n_prims.\")\n",
    "    sites_per_prim = sites_per_supercell // n_prims\n",
    "    scale_site = 1.0 / float(sites_per_prim)\n",
    "\n",
    "    # ---- In-sample prediction using stored ECIs ----\n",
    "    coefs = np.asarray(getattr(ce, \"coefs\"), dtype=np.float64)\n",
    "    y_pred_per_prim_ins = predict_from_features(X, coefs)\n",
    "\n",
    "    in_sample_recomputed = compute_stats(\n",
    "        (y_true_per_prim * scale_site).tolist(),\n",
    "        (y_pred_per_prim_ins * scale_site).tolist(),\n",
    "    )\n",
    "\n",
    "    # ---- Compare + summarize ----\n",
    "    ok = (\n",
    "        int(in_sample_recomputed[\"n\"]) == int(in_sample_stored[\"n\"])\n",
    "        and math.isclose(float(in_sample_recomputed[\"mae_per_site\"]),  float(in_sample_stored[\"mae_per_site\"]),  rel_tol=rtol, abs_tol=atol)\n",
    "        and math.isclose(float(in_sample_recomputed[\"rmse_per_site\"]), float(in_sample_stored[\"rmse_per_site\"]), rel_tol=rtol, abs_tol=atol)\n",
    "        and math.isclose(float(in_sample_recomputed[\"max_abs_per_site\"]), float(in_sample_stored[\"max_abs_per_site\"]), rel_tol=rtol, abs_tol=atol)\n",
    "    )\n",
    "\n",
    "    if verbose:\n",
    "        _print_summary(\n",
    "            ce_key=ce_key,\n",
    "            n=int(in_sample_recomputed[\"n\"]),\n",
    "            stored_in=in_sample_stored,\n",
    "            recomputed_in=in_sample_recomputed,\n",
    "            stored_cv=stored_cv,\n",
    "            atol=atol, rtol=rtol, ok=ok,\n",
    "        )\n",
    "\n",
    "    return ok\n",
    "\n",
    "\n",
    "# ---- Example usage:\n",
    "verify_ce_in_sample(\"76195c946ffef01b43a45fbccfb192c96d55011b69a54b0ccc2d6ff9f6f59bba\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f402c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Mapping, Sequence, cast\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import numpy as np\n",
    "from numpy.typing import NDArray\n",
    "\n",
    "from ase.atoms import Atoms\n",
    "from pymatgen.core import Structure\n",
    "from pymatgen.io.ase import AseAtomsAdaptor\n",
    "\n",
    "# ---- phaseedge imports ----\n",
    "from phaseedge.science.prototypes import PrototypeName\n",
    "from phaseedge.jobs.store_ce_model import lookup_ce_by_key\n",
    "from phaseedge.jobs.decide_relax import lookup_ff_task\n",
    "from phaseedge.science.prototypes import make_prototype\n",
    "from phaseedge.schemas.mixture import sublattices_from_mixtures, Mixture\n",
    "from phaseedge.jobs.train_ce import (\n",
    "    featurize_structures,\n",
    "    predict_from_features,\n",
    "    compute_stats,\n",
    "    _n_replace_sites_from_prototype,\n",
    ")\n",
    "from phaseedge.utils.keys import (\n",
    "    compute_set_id,\n",
    "    rng_for_index,\n",
    "    occ_key_for_atoms,\n",
    ")\n",
    "from phaseedge.utils.rehydrators import rehydrate_ensemble_by_ce_key\n",
    "from smol.cofe import ClusterExpansion\n",
    "\n",
    "\n",
    "# ----------------- helpers: sources & structures -----------------\n",
    "\n",
    "def _source_kind(sources: Sequence[Mapping[str, Any]]) -> str:\n",
    "    kinds = [str(s.get(\"type\", \"\")).lower() for s in sources]\n",
    "    if any(k == \"wl_refined_intent\" for k in kinds):\n",
    "        return \"wl_refined_intent\"\n",
    "    if any(k == \"composition\" for k in kinds):\n",
    "        return \"composition\"\n",
    "    raise RuntimeError(f\"Unsupported sources: {kinds!r}\")\n",
    "\n",
    "def _get_base_ce_key_for_refined(sources: Sequence[Mapping[str, Any]]) -> str:\n",
    "    for s in sources:\n",
    "        if str(s.get(\"type\", \"\")).lower() == \"wl_refined_intent\":\n",
    "            b = s.get(\"base_ce_key\")\n",
    "            if not isinstance(b, str) or not b:\n",
    "                raise RuntimeError(\"wl_refined_intent source missing valid 'base_ce_key'.\")\n",
    "            return b\n",
    "    raise RuntimeError(\"wl_refined_intent source not found.\")\n",
    "\n",
    "def _gather_composition_mixtures(sources: Sequence[Mapping[str, Any]]) -> list[Mixture]:\n",
    "    mixes: list[Mixture] = []\n",
    "    for s in sources:\n",
    "        if str(s.get(\"type\", \"\")).lower() != \"composition\":\n",
    "            continue\n",
    "        for m in s.get(\"mixtures\", []):\n",
    "            mixes.append(Mixture.from_dict({\n",
    "                \"composition_map\": dict(m[\"composition_map\"]),\n",
    "                \"K\": int(m[\"K\"]),\n",
    "                \"seed\": int(m[\"seed\"]),\n",
    "            }))\n",
    "    return mixes\n",
    "\n",
    "def _structure_from_ff_doc(\n",
    "    doc: Mapping[str, Any],\n",
    "    *,\n",
    "    base_ce_key: str,\n",
    ") -> Structure:\n",
    "    \"\"\"\n",
    "    Modern-only structure extraction priority for refined WL path:\n",
    "      1) doc['structure'] as pymatgen dict\n",
    "      2) doc['output']['structure'] as pymatgen dict\n",
    "      3) doc['occ'] -> reconstruct via base CE ensemble\n",
    "    \"\"\"\n",
    "    s_top = doc.get(\"structure\")\n",
    "    if isinstance(s_top, Mapping) and s_top.get(\"@class\") == \"Structure\":\n",
    "        return Structure.from_dict(cast(Mapping[str, Any], s_top))\n",
    "\n",
    "    out = doc.get(\"output\", {})\n",
    "    if isinstance(out, Mapping):\n",
    "        s_out = out.get(\"structure\")\n",
    "        if isinstance(s_out, Mapping) and s_out.get(\"@class\") == \"Structure\":\n",
    "            return Structure.from_dict(cast(Mapping[str, Any], s_out))\n",
    "\n",
    "    occ = doc.get(\"occ\")\n",
    "    if isinstance(occ, list) and all(isinstance(x, (int, np.integer)) for x in occ):\n",
    "        ens = rehydrate_ensemble_by_ce_key(base_ce_key)\n",
    "        occ_arr = np.asarray([int(x) for x in occ], dtype=np.int32)\n",
    "        st = ens.processor.structure_from_occupancy(occ_arr)\n",
    "        if isinstance(st, Structure):\n",
    "            return st\n",
    "        if isinstance(st, Atoms):\n",
    "            return cast(Structure, AseAtomsAdaptor.get_structure(st))\n",
    "\n",
    "    raise RuntimeError(\"Could not extract structure from FF doc (no structure/occ present).\")\n",
    "\n",
    "def _lookup_total_energy_eV(\n",
    "    *, set_id: str, occ_key: str, model: str, relax_cell: bool, dtype: str\n",
    ") -> float:\n",
    "    doc = lookup_ff_task(set_id=set_id, occ_key=occ_key, model=model, relax_cell=relax_cell, dtype=dtype)\n",
    "    if doc is None:\n",
    "        raise RuntimeError(f\"No FF task output found for set_id={set_id} occ_key={occ_key}\")\n",
    "    try:\n",
    "        return float(doc[\"output\"][\"energy\"])\n",
    "    except Exception as exc:\n",
    "        raise RuntimeError(\n",
    "            f\"FF task output missing energy for set_id={set_id} occ_key={occ_key}\"\n",
    "        ) from exc\n",
    "\n",
    "def _fmt_mev(x: float | str) -> str:\n",
    "    return x if isinstance(x, str) else f\"{1e3 * float(x):.3f}\"\n",
    "\n",
    "def _print_comparison_summary(\n",
    "    *,\n",
    "    refined_ce_key: str,\n",
    "    base_ce_key: str,\n",
    "    n: int,\n",
    "    random_on_refined: Mapping[str, Any],\n",
    "    refined_cv: Mapping[str, Any] | None,\n",
    ") -> None:\n",
    "    r_mae = float(random_on_refined[\"mae_per_site\"])\n",
    "    r_rmse = float(random_on_refined[\"rmse_per_site\"])\n",
    "    r_max = float(random_on_refined[\"max_abs_per_site\"])\n",
    "\n",
    "    print(\"═\" * 76)\n",
    "    print(\" Random CE → Refined-set Evaluation (per-site metrics in meV) \".center(76, \"═\"))\n",
    "    print(\"═\" * 76)\n",
    "    print(f\"Refined CE key : {refined_ce_key}\")\n",
    "    print(f\"Base (random) CE key : {base_ce_key}\")\n",
    "    print(f\"samples (n)    : {n}\")\n",
    "    print(\"-\" * 76)\n",
    "    print(\"Random CE on refined training set\")\n",
    "    print(\"Metric         Value\")\n",
    "    print(\"-------------  --------\")\n",
    "    print(f\"MAE            {_fmt_mev(r_mae):>8}\")\n",
    "    print(f\"RMSE           {_fmt_mev(r_rmse):>8}\")\n",
    "    print(f\"Max|err|       {_fmt_mev(r_max):>8}\")\n",
    "    print(\"-\" * 76)\n",
    "\n",
    "    if refined_cv and all(k in refined_cv for k in (\"n\", \"mae_per_site\", \"rmse_per_site\", \"max_abs_per_site\")):\n",
    "        cv_n = int(refined_cv[\"n\"])\n",
    "        cv_mae = float(refined_cv[\"mae_per_site\"])\n",
    "        cv_rmse = float(refined_cv[\"rmse_per_site\"])\n",
    "        cv_max = float(refined_cv[\"max_abs_per_site\"])\n",
    "        print(\"Stored 5-fold CV (from refined CE)\")\n",
    "        print(\"Metric         Value       Δ (random − CV)\")\n",
    "        print(\"-------------  --------    --------------\")\n",
    "        print(f\"n              {cv_n}\")\n",
    "        print(f\"MAE            {_fmt_mev(cv_mae):>8}    {_fmt_mev(r_mae - cv_mae):>8}\")\n",
    "        print(f\"RMSE           {_fmt_mev(cv_rmse):>8}    {_fmt_mev(r_rmse - cv_rmse):>8}\")\n",
    "        print(f\"Max|err|       {_fmt_mev(cv_max):>8}    {_fmt_mev(r_max - cv_max):>8}\")\n",
    "        print(\"-\" * 76)\n",
    "    else:\n",
    "        print(\"Stored 5-fold CV (from refined CE): <not available>\")\n",
    "        print(\"-\" * 76)\n",
    "\n",
    "    print(\"═\" * 76)\n",
    "\n",
    "\n",
    "# ----------------- main entrypoint -----------------\n",
    "\n",
    "def score_random_ce_on_refined_training(\n",
    "    refined_ce_key: str,\n",
    "    *,\n",
    "    atol: float = 1e-6,\n",
    "    rtol: float = 1e-8,\n",
    "    verbose: bool = True,\n",
    ") -> dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Given a **refined** CE key (ensure_ce_from_refined_wl), load the **base/random** CE\n",
    "    used to make it, and compute error metrics of the random CE on the refined CE's\n",
    "    training samples. Print a comparison against the refined CE's stored 5-fold CV.\n",
    "\n",
    "    Returns a dict with keys:\n",
    "      - 'random_on_refined': CEStats for random CE evaluated on refined training set\n",
    "      - 'refined_cv'       : stored five_fold_cv stats from refined CE (or None)\n",
    "      - 'n'                : number of refined training samples evaluated\n",
    "      - 'base_ce_key'      : the random CE key\n",
    "      - 'refined_ce_key'   : the input refined CE key\n",
    "    \"\"\"\n",
    "    # Load refined CE doc (modern schema)\n",
    "    ref_doc = lookup_ce_by_key(refined_ce_key)\n",
    "    if not ref_doc:\n",
    "        raise RuntimeError(f\"No CE found for refined_ce_key={refined_ce_key}\")\n",
    "\n",
    "    sources_ref = cast(Sequence[Mapping[str, Any]], ref_doc[\"sources\"])\n",
    "    if _source_kind(sources_ref) != \"wl_refined_intent\":\n",
    "        raise RuntimeError(\"The provided CE is not a refined WL CE (expected 'wl_refined_intent' source).\")\n",
    "\n",
    "    base_ce_key = _get_base_ce_key_for_refined(sources_ref)\n",
    "    base_doc = lookup_ce_by_key(base_ce_key)\n",
    "    if not base_doc:\n",
    "        raise RuntimeError(f\"Base CE not found for base_ce_key={base_ce_key}\")\n",
    "\n",
    "    # Pull geometry + metadata (assumed identical across base/refined)\n",
    "    prototype = PrototypeName(ref_doc[\"prototype\"])\n",
    "    proto_params = cast(Mapping[str, Any], ref_doc[\"prototype_params\"])\n",
    "    sx, sy, sz = (int(x) for x in ref_doc[\"supercell_diag\"])\n",
    "    supercell_diag = (sx, sy, sz)\n",
    "    model = cast(str, ref_doc[\"model\"])\n",
    "    relax_cell = bool(ref_doc[\"relax_cell\"])\n",
    "    dtype = cast(str, ref_doc[\"dtype\"])\n",
    "    train_refs = cast(Sequence[Mapping[str, Any]], ref_doc[\"train_refs\"])\n",
    "\n",
    "    # Sublattices come from the base/random CE mixtures\n",
    "    base_mixtures = _gather_composition_mixtures(cast(Sequence[Mapping[str, Any]], base_doc[\"sources\"]))\n",
    "    if not base_mixtures:\n",
    "        raise RuntimeError(\"Base CE sources did not contain 'composition' mixtures.\")\n",
    "    sublattices = sublattices_from_mixtures(base_mixtures)\n",
    "\n",
    "    # Build refined training structures + energies (order = stored train_refs)\n",
    "    structures: list[Structure] = []\n",
    "    energies_supercell: list[float] = []\n",
    "    for r in train_refs:\n",
    "        sid = str(r[\"set_id\"])\n",
    "        ok = str(r[\"occ_key\"])\n",
    "        ff_doc = lookup_ff_task(set_id=sid, occ_key=ok, model=model, relax_cell=relax_cell, dtype=dtype)\n",
    "        if ff_doc is None:\n",
    "            raise RuntimeError(f\"Missing FF task for set_id={sid} occ_key={ok}\")\n",
    "        structures.append(_structure_from_ff_doc(ff_doc, base_ce_key=base_ce_key))\n",
    "        energies_supercell.append(float(ff_doc[\"output\"][\"energy\"]))\n",
    "\n",
    "    if len(structures) != len(train_refs):\n",
    "        raise RuntimeError(\"Mismatch in number of reconstructed structures vs. refined train_refs.\")\n",
    "\n",
    "    # Rehydrate **base/random** CE and build features over refined structures\n",
    "    base_ce = ClusterExpansion.from_dict(cast(Mapping[str, Any], base_doc[\"payload\"]))\n",
    "    subspace = base_ce.cluster_subspace\n",
    "    _, X = featurize_structures(\n",
    "        subspace=subspace,\n",
    "        structures=cast(Sequence[Structure], structures),\n",
    "        supercell_diag=supercell_diag,\n",
    "    )\n",
    "\n",
    "    # Targets per primitive/conventional cell\n",
    "    n_prims = int(np.prod(np.asarray(supercell_diag, dtype=int)))\n",
    "    y_true_per_prim: NDArray[np.float64] = (\n",
    "        np.asarray(energies_supercell, dtype=np.float64) / float(n_prims)\n",
    "    ).astype(np.float64, copy=False)\n",
    "\n",
    "    # Per-site scaling\n",
    "    sites_per_supercell = _n_replace_sites_from_prototype(\n",
    "        prototype=prototype,\n",
    "        prototype_params=proto_params,\n",
    "        supercell_diag=supercell_diag,\n",
    "        sublattices=sublattices,\n",
    "    )\n",
    "    if sites_per_supercell % n_prims != 0:\n",
    "        raise RuntimeError(\"sites_per_supercell is not divisible by n_prims.\")\n",
    "    sites_per_prim = sites_per_supercell // n_prims\n",
    "    scale_site = 1.0 / float(sites_per_prim)\n",
    "\n",
    "    # Predict with **base/random** CE ECIs\n",
    "    coefs = np.asarray(getattr(base_ce, \"coefs\"), dtype=np.float64)\n",
    "    y_pred_per_prim = predict_from_features(X, coefs)\n",
    "\n",
    "    random_on_refined = compute_stats(\n",
    "        (y_true_per_prim * scale_site).tolist(),\n",
    "        (y_pred_per_prim * scale_site).tolist(),\n",
    "    )\n",
    "\n",
    "    refined_cv = cast(Mapping[str, Any] | None, cast(Mapping[str, Any], ref_doc[\"stats\"]).get(\"five_fold_cv\"))\n",
    "\n",
    "    if verbose:\n",
    "        _print_comparison_summary(\n",
    "            refined_ce_key=refined_ce_key,\n",
    "            base_ce_key=base_ce_key,\n",
    "            n=int(random_on_refined[\"n\"]),\n",
    "            random_on_refined=random_on_refined,\n",
    "            refined_cv=refined_cv,\n",
    "        )\n",
    "\n",
    "    return {\n",
    "        \"random_on_refined\": random_on_refined,\n",
    "        \"refined_cv\": refined_cv,\n",
    "        \"n\": int(random_on_refined[\"n\"]),\n",
    "        \"base_ce_key\": base_ce_key,\n",
    "        \"refined_ce_key\": refined_ce_key,\n",
    "    }\n",
    "\n",
    "\n",
    "# ---- Example usage:\n",
    "res = score_random_ce_on_refined_training(\"76195c946ffef01b43a45fbccfb192c96d55011b69a54b0ccc2d6ff9f6f59bba\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atomate2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
