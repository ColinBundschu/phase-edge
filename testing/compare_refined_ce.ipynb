{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5880a462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "══════════════════════════════════════════════════════════════════════════════════════\n",
      "══════════════════════════ CE Comparison on Refined Dataset ══════════════════════════\n",
      "══════════════════════════════════════════════════════════════════════════════════════\n",
      "Refined CE key     : 76195c946ffef01b43a45fbccfb192c96d55011b69a54b0ccc2d6ff9f6f59bba\n",
      "Base (composition) : 781041790a68cc664c64278fed25132d984b3bfbc802d207e41d8626818ff737\n",
      "Prototype          : rocksalt\n",
      "Supercell diag     : (3, 3, 3)  (n_prims=27, sites/prim=4)\n",
      "\n",
      "Performance (per-site, meV) — Base CE evaluated on refined dataset  vs  Refined CE stored 5-fold CV\n",
      " Metric              │ Base CE (OOS on refined set) │ Refined CE (5-fold CV, stored) \n",
      "─────────────────────────────────────────────────────────────────────────────────────────\n",
      " n                   │ 102                          │ 102                            \n",
      " MAE (meV/site)      │ 5.420                        │ 1.065                          \n",
      " RMSE (meV/site)     │ 9.472                        │ 1.391                          \n",
      " Max|err| (meV/site) │ 42.037                       │ 3.999                          \n",
      "\n",
      "──────────────────────Design metrics (stored at training time)─────────────────────\n",
      " Metric                      │ Base CE (composition) │ Refined CE (WL refined) \n",
      "───────────────────────────────────────────────────────────────────────────────────\n",
      " n_samples                   │ 102                   │ 102                     \n",
      " n_features                  │ 52                    │ 52                      \n",
      " rank                        │ 49                    │ 49                      \n",
      " sigma_max                   │ 52.8688               │ 49.6998                 \n",
      " sigma_min                   │ 0.0827531             │ 0.0651125               \n",
      " condition_number (κ)        │ 638.873               │ 763.291                 \n",
      " logdet(XᵀX)                 │ -60.3102              │ -34.9883                \n",
      " leverage_mean               │ 0.480392              │ 0.480392                \n",
      " leverage_p95                │ 0.71247               │ 0.748269                \n",
      " leverage_max                │ 0.931477              │ 0.94727                 \n",
      " weighting_applied           │ True                  │ True                    \n",
      " standardization             │ column_zscore         │ column_zscore           \n",
      " zero_variance_feature_count │ 0                     │ 0                       \n",
      "\n",
      "Verdict        : Base CE on refined set is worse than refined (higher MAE & RMSE).\n",
      "══════════════════════════════════════════════════════════════════════════════════════\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'refined_ce_key': '76195c946ffef01b43a45fbccfb192c96d55011b69a54b0ccc2d6ff9f6f59bba',\n",
       " 'base_ce_key': '781041790a68cc664c64278fed25132d984b3bfbc802d207e41d8626818ff737',\n",
       " 'n_prims': 27,\n",
       " 'sites_per_prim': 4,\n",
       " 'base_on_refined_stats_per_site': {'n': 102,\n",
       "  'mae_per_site': 0.005420326681759167,\n",
       "  'rmse_per_site': 0.009472223583991959,\n",
       "  'max_abs_per_site': 0.04203708925292382},\n",
       " 'refined_cv_stats_per_site': {'n': 102,\n",
       "  'mae_per_site': 0.0010650202138921178,\n",
       "  'rmse_per_site': 0.0013909209928694552,\n",
       "  'max_abs_per_site': 0.003998633950208941},\n",
       " 'design_metrics': {'base': {'n_samples': 102,\n",
       "   'n_features': 52,\n",
       "   'rank': 49,\n",
       "   'sigma_max': 52.868765530427,\n",
       "   'sigma_min': 0.0827531270857613,\n",
       "   'condition_number': 638.8733259062996,\n",
       "   'logdet_xtx': -60.31021897498089,\n",
       "   'leverage_mean': 0.480392156862745,\n",
       "   'leverage_max': 0.9314774345458762,\n",
       "   'leverage_p95': 0.7124695355950623,\n",
       "   'weighting_applied': True,\n",
       "   'standardization': 'column_zscore',\n",
       "   'zero_variance_feature_count': 0},\n",
       "  'refined': {'n_samples': 102,\n",
       "   'n_features': 52,\n",
       "   'rank': 49,\n",
       "   'sigma_max': 49.69977208220717,\n",
       "   'sigma_min': 0.06511249358580944,\n",
       "   'condition_number': 763.2908731518569,\n",
       "   'logdet_xtx': -34.98833059346135,\n",
       "   'leverage_mean': 0.4803921568627451,\n",
       "   'leverage_max': 0.947270279884525,\n",
       "   'leverage_p95': 0.7482694602759469,\n",
       "   'weighting_applied': True,\n",
       "   'standardization': 'column_zscore',\n",
       "   'zero_variance_feature_count': 0}}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Any, Mapping, Sequence, cast\n",
    "import numpy as np\n",
    "\n",
    "from ase.atoms import Atoms\n",
    "from pymatgen.core import Structure\n",
    "from pymatgen.io.ase import AseAtomsAdaptor\n",
    "from smol.cofe import ClusterExpansion\n",
    "\n",
    "# ---- phaseedge imports (modern-only) ----\n",
    "from phaseedge.jobs.store_ce_model import lookup_ce_by_key\n",
    "from phaseedge.science.prototypes import PrototypeName\n",
    "from phaseedge.jobs.train_ce import (\n",
    "    featurize_structures,\n",
    "    lookup_train_refs_by_key,\n",
    "    predict_from_features,\n",
    "    compute_stats,\n",
    "    _n_replace_sites_from_prototype,\n",
    ")\n",
    "from phaseedge.schemas.mixture import Mixture, sublattices_from_mixtures\n",
    "from phaseedge.storage.store import lookup_total_energy_eV\n",
    "from phaseedge.utils.keys import occ_key_for_structure\n",
    "\n",
    "\n",
    "# ----------------- small helpers -----------------\n",
    "\n",
    "def fmt_mev(x: float | str) -> str:\n",
    "    if isinstance(x, str):\n",
    "        return x\n",
    "    return f\"{1e3 * float(x):.3f}\"\n",
    "\n",
    "def _gather_composition_mixtures(sources: Sequence[Mapping[str, Any]]) -> list[Mixture]:\n",
    "    mixes: list[Mixture] = []\n",
    "    for s in sources:\n",
    "        if str(s.get(\"type\", \"\")).lower() != \"composition\":\n",
    "            continue\n",
    "        for m in s.get(\"mixtures\", []):\n",
    "            mixes.append(\n",
    "                Mixture.from_dict(\n",
    "                    {\n",
    "                        \"composition_map\": dict(m[\"composition_map\"]),\n",
    "                        \"K\": int(m[\"K\"]),\n",
    "                        \"seed\": int(m[\"seed\"]),\n",
    "                    }\n",
    "                )\n",
    "            )\n",
    "    if not mixes:\n",
    "        raise RuntimeError(\"Expected 'composition' mixtures in sources (modern schema).\")\n",
    "    return mixes\n",
    "\n",
    "\n",
    "def _sublattices_for_doc(doc: Mapping[str, Any]) -> dict[str, tuple[str, ...]]:\n",
    "    \"\"\"\n",
    "    Replaceable sublattices for per-site scaling:\n",
    "      - composition CE: from this doc's mixtures\n",
    "      - wl_refined CE : from the base (composition) CE's mixtures\n",
    "    \"\"\"\n",
    "    sources = cast(Sequence[Mapping[str, Any]], doc[\"sources\"])\n",
    "    if not sources:\n",
    "        raise RuntimeError(\"CE document missing 'sources'.\")\n",
    "    s0 = sources[0]\n",
    "    s_type = str(s0.get(\"type\", \"\")).lower()\n",
    "\n",
    "    if s_type == \"composition\":\n",
    "        return sublattices_from_mixtures(_gather_composition_mixtures(sources))\n",
    "\n",
    "    if s_type.startswith(\"wl_refined\"):\n",
    "        base_ce_key = cast(str, s0[\"base_ce_key\"])\n",
    "        base_doc = lookup_ce_by_key(base_ce_key)\n",
    "        if not base_doc:\n",
    "            raise RuntimeError(f\"Base CE not found for wl_refined source: {base_ce_key}\")\n",
    "        return sublattices_from_mixtures(\n",
    "            _gather_composition_mixtures(cast(Sequence[Mapping[str, Any]], base_doc[\"sources\"]))\n",
    "        )\n",
    "\n",
    "    raise RuntimeError(f\"Unsupported source type in CE doc: {s_type!r}\")\n",
    "\n",
    "\n",
    "def _fmt_f(x: float) -> str:\n",
    "    return f\"{float(x):.6g}\"\n",
    "\n",
    "\n",
    "def _grab(dm: Mapping[str, Any] | None, key: str, default: Any) -> Any:\n",
    "    return default if dm is None else dm.get(key, default)\n",
    "\n",
    "\n",
    "def _print_two_col_table(title: str, col_a_name: str, col_b_name: str, rows: list[tuple[str, str, str]]) -> None:\n",
    "    \"\"\"Pretty side-by-side ASCII table.\"\"\"\n",
    "    w_name = max(len(r[0]) for r in rows + [(\"Metric\", \"\", \"\")])\n",
    "    w_a = max(len(col_a_name), max(len(r[1]) for r in rows))\n",
    "    w_b = max(len(col_b_name), max(len(r[2]) for r in rows))\n",
    "    total = 3 + w_name + 3 + w_a + 3 + w_b + 3\n",
    "\n",
    "    print(title.center(total, \"─\"))\n",
    "    print(f\" {'Metric'.ljust(w_name)} │ {col_a_name.ljust(w_a)} │ {col_b_name.ljust(w_b)} \")\n",
    "    print(\"─\" * total)\n",
    "    for name, a, b in rows:\n",
    "        print(f\" {name.ljust(w_name)} │ {a.ljust(w_a)} │ {b.ljust(w_b)} \")\n",
    "    print(\"\")\n",
    "\n",
    "\n",
    "# ----------------- main comparison -----------------\n",
    "\n",
    "def compare_comp_vs_refined_on_refined_dataset(\n",
    "    refined_ce_key: str,\n",
    "    *,\n",
    "    atol: float = 1e-6,\n",
    "    rtol: float = 1e-8,\n",
    "    verbose: bool = True,\n",
    ") -> dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Compare base composition CE vs. refined WL CE *on the refined dataset*.\n",
    "\n",
    "    - Input: a **refined WL CE key**.\n",
    "    - We evaluate the **base (composition) CE** out-of-sample on the refined CE's training set.\n",
    "    - For the refined CE, we **do NOT recompute**; we display the stored 5-fold CV stats.\n",
    "    - Side-by-side printout includes per-site performance and stored design metrics.\n",
    "    - Returns a dict with both metric bundles.\n",
    "    \"\"\"\n",
    "    # --- Load refined CE doc ---\n",
    "    ref_doc = lookup_ce_by_key(refined_ce_key)\n",
    "    if not ref_doc:\n",
    "        raise RuntimeError(f\"No CE found for refined_ce_key={refined_ce_key}\")\n",
    "\n",
    "    sources = cast(Sequence[Mapping[str, Any]], ref_doc[\"sources\"])\n",
    "    if not sources:\n",
    "        raise RuntimeError(\"Refined CE doc has no sources.\")\n",
    "    s0 = sources[0]\n",
    "    s_type = str(s0.get(\"type\", \"\")).lower()\n",
    "    if not s_type.startswith(\"wl_refined\"):\n",
    "        raise RuntimeError(f\"Provided CE is not a refined WL CE (source.type={s_type!r}).\")\n",
    "\n",
    "    base_ce_key = cast(str, s0[\"base_ce_key\"])\n",
    "    base_doc = lookup_ce_by_key(base_ce_key)\n",
    "    if not base_doc:\n",
    "        raise RuntimeError(f\"Base (composition) CE not found: {base_ce_key}\")\n",
    "\n",
    "    # --- Basic identity checks (should match in the modern pipeline) ---\n",
    "    r_proto = PrototypeName(ref_doc[\"prototype\"])\n",
    "    b_proto = PrototypeName(base_doc[\"prototype\"])\n",
    "    if r_proto != b_proto:\n",
    "        raise RuntimeError(\"Prototype mismatch between refined CE and base composition CE.\")\n",
    "    r_pp = cast(Mapping[str, Any], ref_doc[\"prototype_params\"])\n",
    "    b_pp = cast(Mapping[str, Any], base_doc[\"prototype_params\"])\n",
    "    if dict(r_pp) != dict(b_pp):\n",
    "        raise RuntimeError(\"prototype_params mismatch between refined CE and base composition CE.\")\n",
    "    \n",
    "    xs, ys, zs = ref_doc[\"supercell_diag\"]\n",
    "    r_sc = (int(xs), int(ys), int(zs))\n",
    "    b_xs, b_ys, b_zs = base_doc[\"supercell_diag\"]\n",
    "    b_sc = (int(b_xs), int(b_ys), int(b_zs))\n",
    "    if r_sc != b_sc:\n",
    "        raise RuntimeError(\"supercell_diag mismatch between refined CE and base composition CE.\")\n",
    "\n",
    "    # --- Per-site scaling (replaceable sites / primitive) ---\n",
    "    sublattices = _sublattices_for_doc(base_doc)  # composition-ground truth\n",
    "    n_prims = int(np.prod(np.asarray(r_sc, dtype=int)))\n",
    "    n_sites_const = _n_replace_sites_from_prototype(\n",
    "        prototype=r_proto,\n",
    "        prototype_params=r_pp,\n",
    "        supercell_diag=r_sc,\n",
    "        sublattices=sublattices,\n",
    "    )\n",
    "    if n_sites_const % n_prims != 0:\n",
    "        raise RuntimeError(\"sites_per_supercell not divisible by n_prims (prototype/sublattice mismatch).\")\n",
    "    sites_per_prim = n_sites_const // n_prims\n",
    "    scale_site = 1.0 / float(sites_per_prim)\n",
    "\n",
    "    # --- Build refined dataset from refined CE train_refs (structures + energies) ---\n",
    "    train_refs = lookup_train_refs_by_key(ref_doc[\"dataset_key\"])\n",
    "    if not train_refs or not all(\"structure\" in r for r in train_refs):\n",
    "        raise RuntimeError(\"Refined CE doc missing 'train_refs' with embedded 'structure'.\")\n",
    "\n",
    "    model_r = cast(str, ref_doc[\"model\"])\n",
    "    relax_cell_r = bool(ref_doc[\"relax_cell\"])\n",
    "    dtype_r = cast(str, ref_doc[\"dtype\"])\n",
    "\n",
    "    structures: list[Structure] = []\n",
    "    energies_eV_super: list[float] = []\n",
    "\n",
    "    for i, r in enumerate(train_refs):\n",
    "        pmg_struct = Structure.from_dict(r[\"structure\"])\n",
    "        # sanity: occ_key should round-trip from structure\n",
    "        ok2 = occ_key_for_structure(pmg_struct)\n",
    "        ok_expected = cast(str, r[\"occ_key\"])\n",
    "        if ok2 != ok_expected:\n",
    "            raise RuntimeError(\n",
    "                f\"train_refs[{i}] occ_key mismatch: expected {ok_expected}, rebuilt {ok2}.\"\n",
    "            )\n",
    "\n",
    "        E = lookup_total_energy_eV(\n",
    "            set_id=cast(str, r[\"set_id\"]),\n",
    "            occ_key=ok_expected,\n",
    "            model=model_r,\n",
    "            relax_cell=relax_cell_r,\n",
    "            dtype=dtype_r,\n",
    "        )\n",
    "        if E is None:\n",
    "            raise RuntimeError(f\"Energy not found in store for train_refs[{i}] set_id={r['set_id']}, occ_key={ok_expected[:12]}...\")\n",
    "\n",
    "        structures.append(pmg_struct)\n",
    "        energies_eV_super.append(E)\n",
    "\n",
    "    y_true_per_prim = (np.asarray(energies_eV_super, dtype=np.float64) / float(n_prims)).astype(np.float64, copy=False)\n",
    "\n",
    "    # --- Evaluate BASE CE on the refined dataset ---\n",
    "    base_ce = ClusterExpansion.from_dict(cast(Mapping[str, Any], base_doc[\"payload\"]))\n",
    "    _, X_base = featurize_structures(\n",
    "        subspace=base_ce.cluster_subspace,\n",
    "        structures=structures,\n",
    "        supercell_diag=r_sc,\n",
    "    )\n",
    "    coefs_base = np.asarray(getattr(base_ce, \"coefs\"), dtype=np.float64)\n",
    "    y_pred_per_prim_base = predict_from_features(X_base, coefs_base)\n",
    "\n",
    "    base_on_refined_stats = compute_stats(\n",
    "        (y_true_per_prim * scale_site).tolist(),\n",
    "        (y_pred_per_prim_base * scale_site).tolist(),\n",
    "    )  # per-site\n",
    "\n",
    "    # --- Pull refined CE stored 5-fold CV stats (per-site) ---\n",
    "    ref_stats = cast(Mapping[str, Any], ref_doc[\"stats\"])\n",
    "    ref_cv = cast(Mapping[str, Any], ref_stats[\"five_fold_cv\"])\n",
    "    # also harvest design metrics (stored at training time)\n",
    "    dm_base = cast(Mapping[str, Any] | None, base_doc.get(\"design_metrics\"))\n",
    "    dm_ref = cast(Mapping[str, Any] | None, ref_doc.get(\"design_metrics\"))\n",
    "\n",
    "    # --- Pretty side-by-side printout ---\n",
    "    if verbose:\n",
    "        print(\"═\" * 86)\n",
    "        print(\" CE Comparison on Refined Dataset \".center(86, \"═\"))\n",
    "        print(\"═\" * 86)\n",
    "        print(f\"Refined CE key     : {refined_ce_key}\")\n",
    "        print(f\"Base (composition) : {base_ce_key}\")\n",
    "        print(f\"Prototype          : {r_proto}\")\n",
    "        print(f\"Supercell diag     : {r_sc}  (n_prims={n_prims}, sites/prim={sites_per_prim})\")\n",
    "        print(\"\")\n",
    "\n",
    "        # Performance (per-site, meV)\n",
    "        perf_rows: list[tuple[str, str, str]] = [\n",
    "            (\"n\",                str(int(base_on_refined_stats[\"n\"])), str(int(ref_cv[\"n\"]))),\n",
    "            (\"MAE (meV/site)\",   fmt_mev(base_on_refined_stats[\"mae_per_site\"]), fmt_mev(float(ref_cv[\"mae_per_site\"]))),\n",
    "            (\"RMSE (meV/site)\",  fmt_mev(base_on_refined_stats[\"rmse_per_site\"]), fmt_mev(float(ref_cv[\"rmse_per_site\"]))),\n",
    "            (\"Max|err| (meV/site)\", fmt_mev(base_on_refined_stats[\"max_abs_per_site\"]), fmt_mev(float(ref_cv[\"max_abs_per_site\"]))),\n",
    "        ]\n",
    "        _print_two_col_table(\n",
    "            title=\"Performance (per-site, meV) — Base CE evaluated on refined dataset  vs  Refined CE stored 5-fold CV\",\n",
    "            col_a_name=\"Base CE (OOS on refined set)\",\n",
    "            col_b_name=\"Refined CE (5-fold CV, stored)\",\n",
    "            rows=perf_rows,\n",
    "        )\n",
    "\n",
    "        # Design metrics side-by-side (stored)\n",
    "        def _dm_rows(dm_a: Mapping[str, Any] | None, dm_b: Mapping[str, Any] | None) -> list[tuple[str, str, str]]:\n",
    "            return [\n",
    "                (\"n_samples\",                 str(int(_grab(dm_a, \"n_samples\", -1))),              str(int(_grab(dm_b, \"n_samples\", -1)))),\n",
    "                (\"n_features\",                str(int(_grab(dm_a, \"n_features\", -1))),             str(int(_grab(dm_b, \"n_features\", -1)))),\n",
    "                (\"rank\",                      str(int(_grab(dm_a, \"rank\", -1))),                   str(int(_grab(dm_b, \"rank\", -1)))),\n",
    "                (\"sigma_max\",                 _fmt_f(float(_grab(dm_a, \"sigma_max\", float(\"nan\")))), _fmt_f(float(_grab(dm_b, \"sigma_max\", float(\"nan\"))))),\n",
    "                (\"sigma_min\",                 _fmt_f(float(_grab(dm_a, \"sigma_min\", float(\"nan\")))), _fmt_f(float(_grab(dm_b, \"sigma_min\", float(\"nan\"))))),\n",
    "                (\"condition_number (κ)\",      _fmt_f(float(_grab(dm_a, \"condition_number\", float(\"inf\")))), _fmt_f(float(_grab(dm_b, \"condition_number\", float(\"inf\"))))),\n",
    "                (\"logdet(XᵀX)\",               _fmt_f(float(_grab(dm_a, \"logdet_xtx\", float(\"nan\")))), _fmt_f(float(_grab(dm_b, \"logdet_xtx\", float(\"nan\"))))),\n",
    "                (\"leverage_mean\",             _fmt_f(float(_grab(dm_a, \"leverage_mean\", float(\"nan\")))), _fmt_f(float(_grab(dm_b, \"leverage_mean\", float(\"nan\"))))),\n",
    "                (\"leverage_p95\",              _fmt_f(float(_grab(dm_a, \"leverage_p95\", float(\"nan\")))), _fmt_f(float(_grab(dm_b, \"leverage_p95\", float(\"nan\"))))),\n",
    "                (\"leverage_max\",              _fmt_f(float(_grab(dm_a, \"leverage_max\", float(\"nan\")))), _fmt_f(float(_grab(dm_b, \"leverage_max\", float(\"nan\"))))),\n",
    "                (\"weighting_applied\",         str(bool(_grab(dm_a, \"weighting_applied\", False))),    str(bool(_grab(dm_b, \"weighting_applied\", False)))),\n",
    "                (\"standardization\",           str(_grab(dm_a, \"standardization\", \"none\")),           str(_grab(dm_b, \"standardization\", \"none\"))),\n",
    "                (\"zero_variance_feature_count\", str(int(_grab(dm_a, \"zero_variance_feature_count\", 0))), str(int(_grab(dm_b, \"zero_variance_feature_count\", 0)))),\n",
    "            ]\n",
    "\n",
    "        _print_two_col_table(\n",
    "            title=\"Design metrics (stored at training time)\",\n",
    "            col_a_name=\"Base CE (composition)\",\n",
    "            col_b_name=\"Refined CE (WL refined)\",\n",
    "            rows=_dm_rows(dm_base, dm_ref),\n",
    "        )\n",
    "\n",
    "        # Quick verdict relative to refined CV (optional)\n",
    "        mae_base = float(base_on_refined_stats[\"mae_per_site\"])\n",
    "        mae_ref = float(ref_cv[\"mae_per_site\"])\n",
    "        rmse_base = float(base_on_refined_stats[\"rmse_per_site\"])\n",
    "        rmse_ref = float(ref_cv[\"rmse_per_site\"])\n",
    "\n",
    "        verdict = \"≈ comparable\"\n",
    "        if (mae_base - mae_ref) > max(atol, rtol * abs(mae_ref)) and (rmse_base - rmse_ref) > max(atol, rtol * abs(rmse_ref)):\n",
    "            verdict = \"worse than refined (higher MAE & RMSE)\"\n",
    "        elif (mae_ref - mae_base) > max(atol, rtol * abs(mae_base)) and (rmse_ref - rmse_base) > max(atol, rtol * abs(rmse_base)):\n",
    "            verdict = \"better than refined (lower MAE & RMSE)\"\n",
    "        print(f\"Verdict        : Base CE on refined set is {verdict}.\")\n",
    "        print(\"═\" * 86)\n",
    "\n",
    "    return {\n",
    "        \"refined_ce_key\": refined_ce_key,\n",
    "        \"base_ce_key\": base_ce_key,\n",
    "        \"n_prims\": n_prims,\n",
    "        \"sites_per_prim\": sites_per_prim,\n",
    "        \"base_on_refined_stats_per_site\": base_on_refined_stats,\n",
    "        \"refined_cv_stats_per_site\": ref_cv,\n",
    "        \"design_metrics\": {\n",
    "            \"base\": dm_base,\n",
    "            \"refined\": dm_ref,\n",
    "        },\n",
    "    }\n",
    "\n",
    "\n",
    "# ---- Example:\n",
    "# compare_comp_vs_refined_on_refined_dataset(\"76195c946ffef01b43a45fbccfb192c96d55011b69a54b0ccc2d6ff9f6f59bba\")\n",
    "compare_comp_vs_refined_on_refined_dataset(\"6673ff4bac88871cc8b21fc78e2035b39eac75a31198d839a4daaa75c697286f\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atomate2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
