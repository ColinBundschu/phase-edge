{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5880a462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "══════════════════════════════════════════════════════════════════════════════════════\n",
      "═══════════════════════════════════ CE Comparison ════════════════════════════════════\n",
      "══════════════════════════════════════════════════════════════════════════════════════\n",
      "Refined CE key     : 7a71ede8a97d1ac8bf3eac9fe8b23de419bdf4f5311dabde05cf97f43a343151\n",
      "Base (composition) : 8eaec7c74f156b4f70aac8fe506f2390e6fbf6d8ab72bd51579ec1f4e187d70b\n",
      "Prototype          : spinel\n",
      "Supercell diag     : (2, 2, 2)  (n_prims=8, sites/prim=6)\n",
      "\n",
      "Performance (per-site, meV) — Base CE evaluated on refined dataset  vs  Refined CE stored 5-fold CV\n",
      " Metric              │ Base CE (OOS on refined set) │ Refined CE (5-fold CV, stored) \n",
      "─────────────────────────────────────────────────────────────────────────────────────────\n",
      " n                   │ 150                          │ 150                            \n",
      " MAE (meV/site)      │ 2.040                        │ 1.388                          \n",
      " RMSE (meV/site)     │ 2.685                        │ 1.853                          \n",
      " Max|err| (meV/site) │ 7.497                        │ 7.543                          \n",
      "\n",
      "Verdict A      : Better: Refined CE (5-fold CV, stored) (MAE ↓ by 0.652 meV/site, RMSE ↓ by 0.832 meV/site).\n",
      "Performance (per-site, meV) — Base CE stored 5-fold CV  vs  Refined CE evaluated on base dataset\n",
      " Metric              │ Base CE (5-fold CV, stored) │ Refined CE (OOS on base set) \n",
      "──────────────────────────────────────────────────────────────────────────────────────\n",
      " n                   │ 81                          │ 81                           \n",
      " MAE (meV/site)      │ 2.100                       │ 1.321                        \n",
      " RMSE (meV/site)     │ 2.678                       │ 1.750                        \n",
      " Max|err| (meV/site) │ 7.301                       │ 4.729                        \n",
      "\n",
      "Verdict B      : Better: Refined CE (OOS on base set) (MAE ↓ by 0.779 meV/site, RMSE ↓ by 0.928 meV/site).\n",
      "══════════════════════════════════════════════════════════════════════════════════════\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'refined_ce_key': '7a71ede8a97d1ac8bf3eac9fe8b23de419bdf4f5311dabde05cf97f43a343151',\n",
       " 'base_ce_key': '8eaec7c74f156b4f70aac8fe506f2390e6fbf6d8ab72bd51579ec1f4e187d70b',\n",
       " 'n_prims': 8,\n",
       " 'sites_per_prim': 6,\n",
       " 'base_on_refined_stats_per_site': {'n': 150,\n",
       "  'mae_per_site': 0.0020403153278347355,\n",
       "  'rmse_per_site': 0.002684818706222804,\n",
       "  'max_abs_per_site': 0.007497181785629081},\n",
       " 'refined_cv_stats_per_site': {'n': 150,\n",
       "  'mae_per_site': 0.0013881985473131427,\n",
       "  'rmse_per_site': 0.0018529637675375745,\n",
       "  'max_abs_per_site': 0.007543453513449094},\n",
       " 'refined_on_base_stats_per_site': {'n': 81,\n",
       "  'mae_per_site': 0.001321030774054804,\n",
       "  'rmse_per_site': 0.0017503018533635223,\n",
       "  'max_abs_per_site': 0.0047285378867183425},\n",
       " 'base_cv_stats_per_site': {'n': 81,\n",
       "  'mae_per_site': 0.0020996628371308056,\n",
       "  'rmse_per_site': 0.002677867318356907,\n",
       "  'max_abs_per_site': 0.0073010646872777585},\n",
       " 'design_metrics': {'base': {'n_samples': 81,\n",
       "   'n_features': 53,\n",
       "   'rank': 47,\n",
       "   'sigma_max': 58.19020178270406,\n",
       "   'sigma_min': 0.09872811628060235,\n",
       "   'condition_number': 589.3984811511795,\n",
       "   'logdet_xtx': 46.032672852321205,\n",
       "   'leverage_mean': 0.5802469135802468,\n",
       "   'leverage_max': 0.8338978000975756,\n",
       "   'leverage_p95': 0.821237260223413,\n",
       "   'weighting_applied': True,\n",
       "   'standardization': 'column_zscore',\n",
       "   'zero_variance_feature_count': 1},\n",
       "  'refined': {'n_samples': 150,\n",
       "   'n_features': 53,\n",
       "   'rank': 47,\n",
       "   'sigma_max': 75.00601872961015,\n",
       "   'sigma_min': 0.3000192943878487,\n",
       "   'condition_number': 250.0039835192947,\n",
       "   'logdet_xtx': 110.58899998168745,\n",
       "   'leverage_mean': 0.31333333333333335,\n",
       "   'leverage_max': 0.6123561587053642,\n",
       "   'leverage_p95': 0.49682850874590684,\n",
       "   'weighting_applied': True,\n",
       "   'standardization': 'column_zscore',\n",
       "   'zero_variance_feature_count': 1}}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Any, Mapping, Sequence, cast\n",
    "import numpy as np\n",
    "\n",
    "from pymatgen.core import Structure\n",
    "from smol.cofe import ClusterExpansion\n",
    "\n",
    "# ---- phaseedge imports (modern-only) ----\n",
    "from phaseedge.jobs.store_ce_model import lookup_ce_by_key\n",
    "from phaseedge.science.prototypes import PrototypeName\n",
    "from phaseedge.jobs.train_ce import (\n",
    "    featurize_structures,\n",
    "    lookup_train_refs_by_key,\n",
    "    predict_from_features,\n",
    "    compute_stats,\n",
    "    _n_replace_sites_from_prototype,\n",
    ")\n",
    "from phaseedge.schemas.mixture import Mixture, sublattices_from_mixtures\n",
    "from phaseedge.storage.store import lookup_total_energy_eV\n",
    "from phaseedge.utils.keys import occ_key_for_structure\n",
    "\n",
    "\n",
    "# ----------------- small helpers -----------------\n",
    "\n",
    "def fmt_mev(x: float | str) -> str:\n",
    "    if isinstance(x, str):\n",
    "        return x\n",
    "    return f\"{1e3 * float(x):.3f}\"\n",
    "\n",
    "\n",
    "def _gather_composition_mixtures(sources: Sequence[Mapping[str, Any]]) -> list[Mixture]:\n",
    "    mixes: list[Mixture] = []\n",
    "    for s in sources:\n",
    "        if str(s.get(\"type\", \"\")).lower() != \"composition\":\n",
    "            continue\n",
    "        for m in s.get(\"mixtures\", []):\n",
    "            mixes.append(\n",
    "                Mixture.from_dict(\n",
    "                    {\n",
    "                        \"composition_map\": dict(m[\"composition_map\"]),\n",
    "                        \"K\": int(m[\"K\"]),\n",
    "                        \"seed\": int(m[\"seed\"]),\n",
    "                    }\n",
    "                )\n",
    "            )\n",
    "    if not mixes:\n",
    "        raise RuntimeError(\"Expected 'composition' mixtures in sources (modern schema).\")\n",
    "    return mixes\n",
    "\n",
    "\n",
    "def _sublattices_for_doc(doc: Mapping[str, Any]) -> dict[str, tuple[str, ...]]:\n",
    "    \"\"\"\n",
    "    Replaceable sublattices for per-site scaling:\n",
    "      - composition CE: from this doc's mixtures\n",
    "      - wl_refined CE : from the base (composition) CE's mixtures\n",
    "    \"\"\"\n",
    "    sources = cast(Sequence[Mapping[str, Any]], doc[\"sources\"])\n",
    "    if not sources:\n",
    "        raise RuntimeError(\"CE document missing 'sources'.\")\n",
    "    s0 = sources[0]\n",
    "    s_type = str(s0.get(\"type\", \"\")).lower()\n",
    "\n",
    "    if s_type == \"composition\":\n",
    "        return sublattices_from_mixtures(_gather_composition_mixtures(sources))\n",
    "\n",
    "    if s_type.startswith(\"wl_refined\"):\n",
    "        base_ce_key = cast(str, s0[\"base_ce_key\"])\n",
    "        base_doc = lookup_ce_by_key(base_ce_key)\n",
    "        if not base_doc:\n",
    "            raise RuntimeError(f\"Base CE not found for wl_refined source: {base_ce_key}\")\n",
    "        return sublattices_from_mixtures(\n",
    "            _gather_composition_mixtures(cast(Sequence[Mapping[str, Any]], base_doc[\"sources\"]))\n",
    "        )\n",
    "\n",
    "    raise RuntimeError(f\"Unsupported source type in CE doc: {s_type!r}\")\n",
    "\n",
    "\n",
    "def _fmt_f(x: float) -> str:\n",
    "    return f\"{float(x):.6g}\"\n",
    "\n",
    "\n",
    "def _grab(dm: Mapping[str, Any] | None, key: str, default: Any) -> Any:\n",
    "    return default if dm is None else dm.get(key, default)\n",
    "\n",
    "\n",
    "def _print_two_col_table(title: str, col_a_name: str, col_b_name: str, rows: list[tuple[str, str, str]]) -> None:\n",
    "    \"\"\"Pretty side-by-side ASCII table.\"\"\"\n",
    "    w_name = max(len(r[0]) for r in rows + [(\"Metric\", \"\", \"\")])\n",
    "    w_a = max(len(col_a_name), max(len(r[1]) for r in rows))\n",
    "    w_b = max(len(col_b_name), max(len(r[2]) for r in rows))\n",
    "    total = 3 + w_name + 3 + w_a + 3 + w_b + 3\n",
    "\n",
    "    print(title.center(total, \"─\"))\n",
    "    print(f\" {'Metric'.ljust(w_name)} │ {col_a_name.ljust(w_a)} │ {col_b_name.ljust(w_b)} \")\n",
    "    print(\"─\" * total)\n",
    "    for name, a, b in rows:\n",
    "        print(f\" {name.ljust(w_name)} │ {a.ljust(w_a)} │ {b.ljust(w_b)} \")\n",
    "    print(\"\")\n",
    "\n",
    "\n",
    "def _cmp(a: float, b: float, *, atol: float, rtol: float) -> int:\n",
    "    \"\"\"\n",
    "    Compare a vs b with tolerances.\n",
    "      -1 if a < b beyond tol\n",
    "       0 if |a-b| <= tol\n",
    "       1 if a > b beyond tol\n",
    "    \"\"\"\n",
    "    tol = max(atol, rtol * abs(b))\n",
    "    if a < b - tol:\n",
    "        return -1\n",
    "    if a > b + tol:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "\n",
    "def _better_text(\n",
    "    label_left: str,\n",
    "    label_right: str,\n",
    "    *,\n",
    "    mae_left: float,\n",
    "    rmse_left: float,\n",
    "    mae_right: float,\n",
    "    rmse_right: float,\n",
    "    atol: float,\n",
    "    rtol: float,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Produce a human-readable verdict that *always* names which is better\n",
    "    when there is a clear winner; otherwise reports 'Comparable' or 'No clear winner'.\n",
    "    \"\"\"\n",
    "    c_mae = _cmp(mae_left, mae_right, atol=atol, rtol=rtol)\n",
    "    c_rmse = _cmp(rmse_left, rmse_right, atol=atol, rtol=rtol)\n",
    "\n",
    "    d_mae = abs(mae_left - mae_right)\n",
    "    d_rmse = abs(rmse_left - rmse_right)\n",
    "\n",
    "    if c_mae == -1 and c_rmse == -1:\n",
    "        # left better\n",
    "        return (\n",
    "            f\"Better: {label_left} \"\n",
    "            f\"(MAE ↓ by {fmt_mev(d_mae)} meV/site, RMSE ↓ by {fmt_mev(d_rmse)} meV/site).\"\n",
    "        )\n",
    "    if c_mae == 1 and c_rmse == 1:\n",
    "        # right better\n",
    "        return (\n",
    "            f\"Better: {label_right} \"\n",
    "            f\"(MAE ↓ by {fmt_mev(d_mae)} meV/site, RMSE ↓ by {fmt_mev(d_rmse)} meV/site).\"\n",
    "        )\n",
    "    if c_mae == 0 and c_rmse == 0:\n",
    "        return (\n",
    "            \"Comparable within tolerance \"\n",
    "            f\"(ΔMAE≈{fmt_mev(d_mae)} meV/site, ΔRMSE≈{fmt_mev(d_rmse)} meV/site).\"\n",
    "        )\n",
    "\n",
    "    # mixed case: one metric favors left, the other favors right\n",
    "    pieces: list[str] = []\n",
    "    if c_mae == -1:\n",
    "        pieces.append(f\"{label_left} has lower MAE by {fmt_mev(d_mae)} meV/site\")\n",
    "    elif c_mae == 1:\n",
    "        pieces.append(f\"{label_right} has lower MAE by {fmt_mev(d_mae)} meV/site\")\n",
    "    if c_rmse == -1:\n",
    "        pieces.append(f\"{label_left} has lower RMSE by {fmt_mev(d_rmse)} meV/site\")\n",
    "    elif c_rmse == 1:\n",
    "        pieces.append(f\"{label_right} has lower RMSE by {fmt_mev(d_rmse)} meV/site\")\n",
    "    return \"No clear winner: \" + \"; \".join(pieces) + \".\"\n",
    "\n",
    "\n",
    "def _load_structures_and_energies(\n",
    "    *,\n",
    "    dataset_key: str,\n",
    "    model: str,\n",
    "    relax_cell: bool,\n",
    "    dtype: str,\n",
    ") -> tuple[list[Structure], list[float]]:\n",
    "    \"\"\"\n",
    "    Load structures and *supercell* total energies for a dataset key.\n",
    "    \"\"\"\n",
    "    train_refs = lookup_train_refs_by_key(dataset_key)\n",
    "    if not train_refs or not all(\"structure\" in r for r in train_refs):\n",
    "        raise RuntimeError(\n",
    "            f\"Dataset {dataset_key} missing 'train_refs' with embedded 'structure'.\"\n",
    "        )\n",
    "\n",
    "    structures: list[Structure] = []\n",
    "    energies_eV_super: list[float] = []\n",
    "\n",
    "    for i, r in enumerate(train_refs):\n",
    "        pmg_struct = Structure.from_dict(r[\"structure\"])\n",
    "        # sanity: occ_key should round-trip from structure\n",
    "        ok2 = occ_key_for_structure(pmg_struct)\n",
    "        ok_expected = cast(str, r[\"occ_key\"])\n",
    "        if ok2 != ok_expected:\n",
    "            raise RuntimeError(\n",
    "                f\"train_refs[{i}] occ_key mismatch: expected {ok_expected}, rebuilt {ok2}.\"\n",
    "            )\n",
    "\n",
    "        E = lookup_total_energy_eV(\n",
    "            set_id=cast(str, r[\"set_id\"]),\n",
    "            occ_key=ok_expected,\n",
    "            model=model,\n",
    "            relax_cell=relax_cell,\n",
    "            dtype=dtype,\n",
    "        )\n",
    "        if E is None:\n",
    "            raise RuntimeError(\n",
    "                f\"Energy not found in store for train_refs[{i}] set_id={r['set_id']}, occ_key={ok_expected[:12]}...\"\n",
    "            )\n",
    "\n",
    "        structures.append(pmg_struct)\n",
    "        energies_eV_super.append(E)\n",
    "\n",
    "    return structures, energies_eV_super\n",
    "\n",
    "\n",
    "def _predict_per_prim(\n",
    "    ce: ClusterExpansion,\n",
    "    *,\n",
    "    structures: list[Structure],\n",
    "    supercell_diag: tuple[int, int, int],\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Predict energy per-primitive using CE coefficients and features.\n",
    "    \"\"\"\n",
    "    _, X = featurize_structures(\n",
    "        subspace=ce.cluster_subspace,\n",
    "        structures=structures,\n",
    "        supercell_diag=supercell_diag,\n",
    "    )\n",
    "    coefs = np.asarray(getattr(ce, \"coefs\"), dtype=np.float64)\n",
    "    y_pred_per_prim = predict_from_features(X, coefs)\n",
    "    return y_pred_per_prim\n",
    "\n",
    "\n",
    "# ----------------- main comparison -----------------\n",
    "\n",
    "def compare_comp_vs_refined_on_refined_dataset(\n",
    "    refined_ce_key: str,\n",
    "    *,\n",
    "    atol: float = 1e-6,\n",
    "    rtol: float = 1e-8,\n",
    "    verbose: bool = True,\n",
    ") -> dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Cross-compare base composition CE and refined WL CE.\n",
    "\n",
    "    Inputs:\n",
    "      - refined_ce_key: key of a **refined WL CE**.\n",
    "\n",
    "    What it prints (per-site, meV), refined is always the RIGHT column:\n",
    "      1) Base CE evaluated on the *refined* dataset  (left)  vs  Refined CE stored 5-fold CV  (right)\n",
    "      2) Base CE stored 5-fold CV                     (left)  vs  Refined CE evaluated on the *base* dataset (right)\n",
    "\n",
    "    Returns (dict):\n",
    "      - refined_ce_key, base_ce_key, n_prims, sites_per_prim\n",
    "      - base_on_refined_stats_per_site\n",
    "      - refined_cv_stats_per_site\n",
    "      - refined_on_base_stats_per_site\n",
    "      - base_cv_stats_per_site\n",
    "      - design_metrics: {base, refined}\n",
    "    \"\"\"\n",
    "    # --- Load refined CE doc ---\n",
    "    ref_doc = lookup_ce_by_key(refined_ce_key)\n",
    "    if not ref_doc:\n",
    "        raise RuntimeError(f\"No CE found for refined_ce_key={refined_ce_key}\")\n",
    "\n",
    "    sources = cast(Sequence[Mapping[str, Any]], ref_doc[\"sources\"])\n",
    "    if not sources:\n",
    "        raise RuntimeError(\"Refined CE doc has no sources.\")\n",
    "    s0 = sources[0]\n",
    "    s_type = str(s0.get(\"type\", \"\")).lower()\n",
    "    if not s_type.startswith(\"wl_refined\"):\n",
    "        raise RuntimeError(f\"Provided CE is not a refined WL CE (source.type={s_type!r}).\")\n",
    "\n",
    "    base_ce_key = cast(str, s0[\"base_ce_key\"])\n",
    "    base_doc = lookup_ce_by_key(base_ce_key)\n",
    "    if not base_doc:\n",
    "        raise RuntimeError(f\"Base (composition) CE not found: {base_ce_key}\")\n",
    "\n",
    "    # --- Basic identity checks (should match in the modern pipeline) ---\n",
    "    r_proto = PrototypeName(ref_doc[\"prototype\"])\n",
    "    b_proto = PrototypeName(base_doc[\"prototype\"])\n",
    "    if r_proto != b_proto:\n",
    "        raise RuntimeError(\"Prototype mismatch between refined CE and base composition CE.\")\n",
    "    r_pp = cast(Mapping[str, Any], ref_doc[\"prototype_params\"])\n",
    "    b_pp = cast(Mapping[str, Any], base_doc[\"prototype_params\"])\n",
    "    if dict(r_pp) != dict(b_pp):\n",
    "        raise RuntimeError(\"prototype_params mismatch between refined CE and base composition CE.\")\n",
    "    \n",
    "    xs, ys, zs = ref_doc[\"supercell_diag\"]\n",
    "    r_sc = (int(xs), int(ys), int(zs))\n",
    "    b_xs, b_ys, b_zs = base_doc[\"supercell_diag\"]\n",
    "    b_sc = (int(b_xs), int(b_ys), int(b_zs))\n",
    "    if r_sc != b_sc:\n",
    "        raise RuntimeError(\"supercell_diag mismatch between refined CE and base composition CE.\")\n",
    "\n",
    "    # --- Per-site scaling (replaceable sites / primitive) ---\n",
    "    sublattices = _sublattices_for_doc(base_doc)  # composition-ground truth\n",
    "    n_prims = int(np.prod(np.asarray(r_sc, dtype=int)))\n",
    "    n_sites_const = _n_replace_sites_from_prototype(\n",
    "        prototype=r_proto,\n",
    "        prototype_params=r_pp,\n",
    "        supercell_diag=r_sc,\n",
    "        sublattices=sublattices,\n",
    "    )\n",
    "    if n_sites_const % n_prims != 0:\n",
    "        raise RuntimeError(\"sites_per_supercell not divisible by n_prims (prototype/sublattice mismatch).\")\n",
    "    sites_per_prim = n_sites_const // n_prims\n",
    "    scale_site = 1.0 / float(sites_per_prim)\n",
    "\n",
    "    # --- Build refined dataset from refined CE train_refs (structures + energies) ---\n",
    "    model_r = cast(str, ref_doc[\"model\"])\n",
    "    relax_cell_r = bool(ref_doc[\"relax_cell\"])\n",
    "    dtype_r = cast(str, ref_doc[\"dtype\"])\n",
    "\n",
    "    structures_refined, energies_eV_super_refined = _load_structures_and_energies(\n",
    "        dataset_key=cast(str, ref_doc[\"dataset_key\"]),\n",
    "        model=model_r,\n",
    "        relax_cell=relax_cell_r,\n",
    "        dtype=dtype_r,\n",
    "    )\n",
    "    y_true_per_prim_refined = (np.asarray(energies_eV_super_refined, dtype=np.float64) / float(n_prims)).astype(np.float64, copy=False)\n",
    "\n",
    "    # --- Evaluate BASE CE on the refined dataset ---\n",
    "    base_ce = ClusterExpansion.from_dict(cast(Mapping[str, Any], base_doc[\"payload\"]))\n",
    "    y_pred_per_prim_base_on_refined = _predict_per_prim(\n",
    "        base_ce,\n",
    "        structures=structures_refined,\n",
    "        supercell_diag=r_sc,\n",
    "    )\n",
    "    base_on_refined_stats = compute_stats(\n",
    "        (y_true_per_prim_refined * scale_site).tolist(),\n",
    "        (y_pred_per_prim_base_on_refined * scale_site).tolist(),\n",
    "    )  # per-site\n",
    "\n",
    "    # --- Pull refined CE stored 5-fold CV stats (per-site) ---\n",
    "    ref_stats = cast(Mapping[str, Any], ref_doc[\"stats\"])\n",
    "    ref_cv = cast(Mapping[str, Any], ref_stats[\"five_fold_cv\"])\n",
    "    # also harvest design metrics (stored at training time)\n",
    "    dm_base = cast(Mapping[str, Any] | None, base_doc.get(\"design_metrics\"))\n",
    "    dm_ref = cast(Mapping[str, Any] | None, ref_doc.get(\"design_metrics\"))\n",
    "\n",
    "    # --- Evaluate REFINED CE on the base dataset ---\n",
    "    model_b = cast(str, base_doc[\"model\"])\n",
    "    relax_cell_b = bool(base_doc[\"relax_cell\"])\n",
    "    dtype_b = cast(str, base_doc[\"dtype\"])\n",
    "\n",
    "    structures_base, energies_eV_super_base = _load_structures_and_energies(\n",
    "        dataset_key=cast(str, base_doc[\"dataset_key\"]),\n",
    "        model=model_b,\n",
    "        relax_cell=relax_cell_b,\n",
    "        dtype=dtype_b,\n",
    "    )\n",
    "    y_true_per_prim_base = (np.asarray(energies_eV_super_base, dtype=np.float64) / float(n_prims)).astype(np.float64, copy=False)\n",
    "\n",
    "    refined_ce = ClusterExpansion.from_dict(cast(Mapping[str, Any], ref_doc[\"payload\"]))\n",
    "    y_pred_per_prim_refined_on_base = _predict_per_prim(\n",
    "        refined_ce,\n",
    "        structures=structures_base,\n",
    "        supercell_diag=b_sc,  # == r_sc\n",
    "    )\n",
    "    refined_on_base_stats = compute_stats(\n",
    "        (y_true_per_prim_base * scale_site).tolist(),\n",
    "        (y_pred_per_prim_refined_on_base * scale_site).tolist(),\n",
    "    )  # per-site\n",
    "\n",
    "    # --- Base CE stored 5-fold CV (per-site) ---\n",
    "    base_stats = cast(Mapping[str, Any], base_doc[\"stats\"])\n",
    "    base_cv = cast(Mapping[str, Any], base_stats[\"five_fold_cv\"])\n",
    "\n",
    "    # --- Pretty side-by-side printout (refined is ALWAYS right column) ---\n",
    "    if verbose:\n",
    "        print(\"═\" * 86)\n",
    "        print(\" CE Comparison \".center(86, \"═\"))\n",
    "        print(\"═\" * 86)\n",
    "        print(f\"Refined CE key     : {refined_ce_key}\")\n",
    "        print(f\"Base (composition) : {base_ce_key}\")\n",
    "        print(f\"Prototype          : {r_proto}\")\n",
    "        print(f\"Supercell diag     : {r_sc}  (n_prims={n_prims}, sites/prim={sites_per_prim})\")\n",
    "        print(\"\")\n",
    "\n",
    "        # 1) Performance: Base CE on refined dataset (left) vs Refined CE stored CV (right)\n",
    "        left_label_1 = \"Base CE (OOS on refined set)\"\n",
    "        right_label_1 = \"Refined CE (5-fold CV, stored)\"\n",
    "        perf_rows_1: list[tuple[str, str, str]] = [\n",
    "            (\"n\",                   str(int(base_on_refined_stats[\"n\"])),                 str(int(ref_cv[\"n\"]))),\n",
    "            (\"MAE (meV/site)\",      fmt_mev(base_on_refined_stats[\"mae_per_site\"]),       fmt_mev(float(ref_cv[\"mae_per_site\"]))),\n",
    "            (\"RMSE (meV/site)\",     fmt_mev(base_on_refined_stats[\"rmse_per_site\"]),      fmt_mev(float(ref_cv[\"rmse_per_site\"]))),\n",
    "            (\"Max|err| (meV/site)\", fmt_mev(base_on_refined_stats[\"max_abs_per_site\"]),   fmt_mev(float(ref_cv[\"max_abs_per_site\"]))),\n",
    "        ]\n",
    "        _print_two_col_table(\n",
    "            title=\"Performance (per-site, meV) — Base CE evaluated on refined dataset  vs  Refined CE stored 5-fold CV\",\n",
    "            col_a_name=left_label_1,\n",
    "            col_b_name=right_label_1,\n",
    "            rows=perf_rows_1,\n",
    "        )\n",
    "\n",
    "        verdict1 = _better_text(\n",
    "            left_label_1, right_label_1,\n",
    "            mae_left=float(base_on_refined_stats[\"mae_per_site\"]),\n",
    "            rmse_left=float(base_on_refined_stats[\"rmse_per_site\"]),\n",
    "            mae_right=float(ref_cv[\"mae_per_site\"]),\n",
    "            rmse_right=float(ref_cv[\"rmse_per_site\"]),\n",
    "            atol=atol, rtol=rtol,\n",
    "        )\n",
    "        print(f\"Verdict A      : {verdict1}\")\n",
    "\n",
    "        # 2) Performance: Base CE stored CV (left) vs Refined CE on base dataset (right)\n",
    "        left_label_2 = \"Base CE (5-fold CV, stored)\"\n",
    "        right_label_2 = \"Refined CE (OOS on base set)\"\n",
    "        perf_rows_2: list[tuple[str, str, str]] = [\n",
    "            (\"n\",                   str(int(base_cv[\"n\"])),                               str(int(refined_on_base_stats[\"n\"]))),\n",
    "            (\"MAE (meV/site)\",      fmt_mev(float(base_cv[\"mae_per_site\"])),              fmt_mev(refined_on_base_stats[\"mae_per_site\"])),\n",
    "            (\"RMSE (meV/site)\",     fmt_mev(float(base_cv[\"rmse_per_site\"])),             fmt_mev(refined_on_base_stats[\"rmse_per_site\"])),\n",
    "            (\"Max|err| (meV/site)\", fmt_mev(float(base_cv[\"max_abs_per_site\"])),          fmt_mev(refined_on_base_stats[\"max_abs_per_site\"])),\n",
    "        ]\n",
    "        _print_two_col_table(\n",
    "            title=\"Performance (per-site, meV) — Base CE stored 5-fold CV  vs  Refined CE evaluated on base dataset\",\n",
    "            col_a_name=left_label_2,\n",
    "            col_b_name=right_label_2,\n",
    "            rows=perf_rows_2,\n",
    "        )\n",
    "\n",
    "        verdict2 = _better_text(\n",
    "            left_label_2, right_label_2,\n",
    "            mae_left=float(base_cv[\"mae_per_site\"]),\n",
    "            rmse_left=float(base_cv[\"rmse_per_site\"]),\n",
    "            mae_right=float(refined_on_base_stats[\"mae_per_site\"]),\n",
    "            rmse_right=float(refined_on_base_stats[\"rmse_per_site\"]),\n",
    "            atol=atol, rtol=rtol,\n",
    "        )\n",
    "        print(f\"Verdict B      : {verdict2}\")\n",
    "        print(\"═\" * 86)\n",
    "\n",
    "    return {\n",
    "        \"refined_ce_key\": refined_ce_key,\n",
    "        \"base_ce_key\": base_ce_key,\n",
    "        \"n_prims\": n_prims,\n",
    "        \"sites_per_prim\": sites_per_prim,\n",
    "        \"base_on_refined_stats_per_site\": base_on_refined_stats,\n",
    "        \"refined_cv_stats_per_site\": ref_cv,\n",
    "        \"refined_on_base_stats_per_site\": refined_on_base_stats,\n",
    "        \"base_cv_stats_per_site\": base_cv,\n",
    "        \"design_metrics\": {\n",
    "            \"base\": dm_base,\n",
    "            \"refined\": dm_ref,\n",
    "        },\n",
    "    }\n",
    "\n",
    "\n",
    "# ---- Example:\n",
    "# compare_comp_vs_refined_on_refined_dataset(\"12f34e8ed8bb3e43a2abbf4d881825cb507a718dd7011c5b99b9c192dc8a7b89\") #MgAl2O4 2x2x2 refined\n",
    "# compare_comp_vs_refined_on_refined_dataset(\"2eb70b34e7d7cc7e2ac8f751ba70a77e3cddaa9b01f1957e6cfb8d9707cea9ed\") # MgFeO2 3x3x3 refined\n",
    "# compare_comp_vs_refined_on_refined_dataset(\"b44b07bb0df364ea641ba588b02cbdf759961a49105d9bd9eb8595f65332dac0\") # MgGaO2 2x2x2 refined\n",
    "compare_comp_vs_refined_on_refined_dataset(\"7a71ede8a97d1ac8bf3eac9fe8b23de419bdf4f5311dabde05cf97f43a343151\") # ZnAl2O4 2x2x2 refined\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atomate2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
